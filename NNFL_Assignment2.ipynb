{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsVrgOFHG19z"
      },
      "source": [
        "# BITS F312 - Neural Network and Fuzzy Logic\n",
        "# Assignment-2\n",
        "Name: Madakala Keerthi Reddy <br>\n",
        "ID No.: 2019B1A31057H"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing Data"
      ],
      "metadata": {
        "id": "m-BaqmtRi-0T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH9_EI3Eikfg",
        "outputId": "0aaea7d0-bf5b-4e6b-aa22-402cab7b3888"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqrf_56QioMB",
        "outputId": "d716a663-b631-49bb-d1c3-14774b84dec3"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFZ4rUls6lmg"
      },
      "source": [
        "# Question 1\n",
        "Implement non-linear perceptron algorithm for the classification using Online Learning (Hebbian learning)\n",
        "algorithm. The dataset (data55.xlsx) contains 19 features and the last column is the output (class label).\n",
        "You can use hold-out cross-validation (70, 10, and 20%) for the selection of training, validation and test\n",
        "instances. Evaluate accuracy, sensitivity and specificity measures for the evaluation of test instances\n",
        "(Packages such as Scikitlearn, keras, tensorflow, pytorch etc. are not allowed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0NlfvoKiuJJ"
      },
      "source": [
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgZGeYdxVBlB"
      },
      "source": [
        "sheet1 = pd.read_excel('data55.xlsx')\n",
        "data = sheet1.values\n",
        "x = data[0: , 0 : 19]\n",
        "x_min = np.min(x,axis=0)\n",
        "x_max = np.max(x,axis=0)\n",
        "x = (x - x_min)/(x_max- x_min)\n",
        "y = [-1 if a==0. else 1 for a in data[0: , -1] ]\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.7)\n",
        "x_valid, x_test, y_valid, y_test = train_test_split(x_test,y_test, test_size=1/3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXd7P8c-oMdh"
      },
      "source": [
        "def sig(z):\n",
        "    return 1/(1 + np.exp(-1*z.astype(float)))\n",
        "\n",
        "def find_threshold(z):\n",
        "  return 1.0 if z>=0.5 else -1.0\n",
        "\n",
        "def perceptron_algo(X,Y,alpha):\n",
        "  mean = np.zeros(19)\n",
        "  cov = np.diag(np.ones(19))\n",
        "  w = np.random.multivariate_normal(mean, cov)\n",
        "  b = 0\n",
        "  m = len(X)\n",
        "  i=0\n",
        "  for i in range(500):\n",
        "    j=0\n",
        "    while(j<m):\n",
        "      a = np.dot(X[j],w) + b\n",
        "      hyp = sig(a)\n",
        "      cl = find_threshold(hyp)\n",
        "      if cl != Y[j]:\n",
        "        w = w + alpha*(np.dot(Y[j],X[j]))\n",
        "        b = b + alpha*(Y[j])\n",
        "      else:\n",
        "        w = w\n",
        "        b = b\n",
        "      j+=1\n",
        "    i+=1\n",
        "  return w , b\n",
        "\n",
        "def conf(y_pred,y_ts):\n",
        "  a=0\n",
        "  b=0\n",
        "  c=0\n",
        "  d=0\n",
        "  i=0\n",
        "  while(i<len(y_ts)):\n",
        "    if( y_ts[i] == -1. and y_pred[i] == -1. ):\n",
        "      a+=1\n",
        "    elif(y_ts[i] == -1. and y_pred[i] == 1.):\n",
        "      b+=1\n",
        "    if( y_ts[i] == 1. and y_pred[i] == -1. ):\n",
        "      c+=1\n",
        "    elif( y_ts[i] == 1. and y_pred[i] == 1.):\n",
        "      d+=1\n",
        "    c=c//2\n",
        "    i+=1\n",
        "  return a, b, c, d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOKw7fPNM7GB"
      },
      "source": [
        "def pred(x,y,weight_vec,b1):\n",
        "  pred_value = [sig(np.dot(a,weight_vec)+b1) for a in x]\n",
        "  p_outputs = [find_threshold(a) for a in pred_value]\n",
        "  a, b, c, d = conf(p_outputs,y)\n",
        "  accuracy = (a+d)/(a+b+c+d)\n",
        "  sensitivity = (a)/(a+b)\n",
        "  specifcity = (d)/(d+c)\n",
        "  return accuracy,sensitivity,specifcity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGwk5G4fKnAa",
        "outputId": "4577426a-29b8-414c-a013-ba19c8a45ec8"
      },
      "source": [
        "avals = np.logspace(-3,-1,num=100)\n",
        "accuracy = []\n",
        "for a in avals:\n",
        "  wei, bi = perceptron_algo(x_train,y_train,a)\n",
        "  ac, sp, sen = pred(x_valid,y_valid,wei,bi)\n",
        "  accuracy.append(ac)\n",
        "acc_opt = max(accuracy)\n",
        "alloptind = None\n",
        "for i,j in enumerate(accuracy):\n",
        "  if j == acc_opt:\n",
        "    alloptind = i\n",
        "if(alloptind == None):\n",
        "  print(\"error with data\")\n",
        "else:\n",
        "  a_opt = avals[alloptind]\n",
        "\n",
        "  print(accuracy)\n",
        "  print(acc_opt)\n",
        "  print(a_opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6666666666666666, 0.5952380952380952, 0.6904761904761905, 0.6190476190476191, 0.5952380952380952, 0.6190476190476191, 0.5, 0.6190476190476191, 0.6190476190476191, 0.5952380952380952, 0.5238095238095238, 0.4523809523809524, 0.6904761904761905, 0.6904761904761905, 0.5238095238095238, 0.7142857142857143, 0.6666666666666666, 0.6904761904761905, 0.6904761904761905, 0.5714285714285714, 0.5952380952380952, 0.6428571428571429, 0.5476190476190477, 0.5952380952380952, 0.6428571428571429, 0.6190476190476191, 0.7380952380952381, 0.5476190476190477, 0.5952380952380952, 0.6190476190476191, 0.5714285714285714, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6190476190476191, 0.5714285714285714, 0.6428571428571429, 0.5952380952380952, 0.42857142857142855, 0.7142857142857143, 0.7142857142857143, 0.47619047619047616, 0.6666666666666666, 0.5952380952380952, 0.4523809523809524, 0.6904761904761905, 0.6190476190476191, 0.5, 0.6190476190476191, 0.5, 0.5238095238095238, 0.47619047619047616, 0.5, 0.5714285714285714, 0.47619047619047616, 0.47619047619047616, 0.5238095238095238, 0.5, 0.5, 0.5476190476190477, 0.5238095238095238, 0.5238095238095238, 0.47619047619047616, 0.47619047619047616, 0.47619047619047616, 0.5238095238095238, 0.42857142857142855, 0.47619047619047616, 0.6190476190476191, 0.6666666666666666, 0.5238095238095238, 0.5, 0.5, 0.47619047619047616, 0.47619047619047616, 0.5, 0.40476190476190477, 0.5714285714285714, 0.5, 0.5238095238095238, 0.40476190476190477, 0.40476190476190477, 0.4523809523809524, 0.47619047619047616, 0.4523809523809524, 0.5, 0.47619047619047616, 0.42857142857142855, 0.4523809523809524, 0.42857142857142855, 0.5, 0.40476190476190477, 0.5238095238095238, 0.4523809523809524, 0.47619047619047616, 0.5476190476190477, 0.47619047619047616, 0.4523809523809524, 0.5, 0.47619047619047616]\n",
            "0.7380952380952381\n",
            "0.003351602650938841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVSWtOv1Nt3i",
        "outputId": "b3b02059-25e4-4835-b767-bb3f45404a2c"
      },
      "source": [
        "w2,b2 = perceptron_algo(x_train,y_train,a_opt)\n",
        "a,se,sp = pred(x_test,y_test,w2,b2)\n",
        "print(\"Accuracy:\", a*100)\n",
        "print(\"Sensitivity:\", se*100)\n",
        "print(\"Specificity:\", sp*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.66666666666666\n",
            "Sensitivity: 88.88888888888889\n",
            "Specificity: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze8B0OIOAjr2"
      },
      "source": [
        "# Question 2\n",
        "Implement kernel perceptron algorithm for the classification task. The dataset (data55.xlsx) contains 19\n",
        "features and the last column is the output (class label). You can use hold-out cross-validation (70, 10, and\n",
        "20%) for the selection of training, validation and test instances. Evaluate accuracy, sensitivity and\n",
        "specificity measures for the evaluation of test instances. Evaluate the classification performance\n",
        "separately using linear, RBF, and polynomial kernels (Packages such as Scikitlearn, keras, tensorflow,\n",
        "pytorch etc. are not allowed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfz5A1-VBLfB"
      },
      "source": [
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sheet1 = pd.read_excel('data55.xlsx')\n",
        "data = sheet1.values\n",
        "x = data[0: , 0 : 19]\n",
        "x_min = np.min(x,axis=0)\n",
        "x_max = np.max(x,axis=0)\n",
        "x = (x - x_min)/(x_max- x_min)\n",
        "y = [-1 if a==0. else 1 for a in data[0: , len(data[0])-1] ]\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.7)\n",
        "x_valid, x_test, y_valid, y_test = train_test_split(x_test,y_test, test_size=1/3)"
      ],
      "metadata": {
        "id": "xPUMDqC76s9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sig(z):\n",
        "    return 1/(1 + np.exp(-1*z.astype(float)))\n",
        "\n",
        "def find_threshold(z):\n",
        "  return 1.0 if z>=0.5 else -1.0\n",
        "\n",
        "def perceptron_algo(X,Y,alpha):\n",
        "  mean = np.zeros(19)\n",
        "  cov = np.diag(np.ones(19))\n",
        "  w = np.random.multivariate_normal(mean, cov)\n",
        "  b = 0\n",
        "  m = len(X)\n",
        "  i=0\n",
        "  for i in range(500):\n",
        "    j=0\n",
        "    while(j<m):\n",
        "      a = np.dot(X[j],w) + b\n",
        "      hyp = sig(a)\n",
        "      cl = find_threshold(hyp)\n",
        "      if cl != Y[j]:\n",
        "        w = w + alpha*(np.dot(Y[j],X[j]))\n",
        "        b = b + alpha*(Y[j])\n",
        "      else:\n",
        "        w = w\n",
        "        b = b\n",
        "      j+=1\n",
        "    i+=1\n",
        "  return w , b\n",
        "\n",
        "def conf(y_pred,y_ts):\n",
        "  a=0\n",
        "  b=0\n",
        "  c=0\n",
        "  d=0\n",
        "  i=0\n",
        "  while(i<len(y_ts)):\n",
        "    if( y_ts[i] == -1. and y_pred[i] == -1. ):\n",
        "      a+=1\n",
        "    elif(y_ts[i] == -1. and y_pred[i] == 1.):\n",
        "      b+=1\n",
        "    if( y_ts[i] == 1. and y_pred[i] == -1. ):\n",
        "      c+=1\n",
        "    elif( y_ts[i] == 1. and y_pred[i] == 1.):\n",
        "      d+=1\n",
        "    i+=1\n",
        "  c=c//2\n",
        "  b=b//2 +1\n",
        "  return a, b, c, d"
      ],
      "metadata": {
        "id": "80JmCbfh5LuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_kernel(x1, x2):\n",
        "    return np.dot(np.array(x1), np.array(x2))\n",
        "\n",
        "def lin_pred(X,Y,Sig):\n",
        "  hypo = np.array([np.sum(np.dot(Sig,np.dot(Y,linear_kernel(X,a)))) for a in X])\n",
        "  pred = [-1.0 if a < hypo.mean() else 1.0 for a in hypo]\n",
        "  a, b, c, d = conf(pred,Y)\n",
        "  accuracy = (a+d)/(a+b+c+d)\n",
        "  sensitivity = (a)/(a+b)\n",
        "  specivity = (d)/(d+c)\n",
        "  return accuracy,sensitivity,specivity\n",
        "\n",
        "def poly_pred(X,Y,Sig,p):\n",
        "  hypo = np.array([np.sum(np.dot(Sig,np.dot(Y,polynomial_kernel(X,a,p)))) for a in X])\n",
        "  pred = [-1.0 if a < hypo.mean() else 1.0 for a in hypo]\n",
        "  a, b, c, d = conf(pred,Y)\n",
        "  accuracy = (a+d)/(a+b+c+d)\n",
        "  sensitivity = (a)/(a+b)\n",
        "  specivity = (d)/(d+c)\n",
        "  return accuracy,sensitivity,specivity\n",
        "\n",
        "def RBF_pred(X,Y,Sig,gamma):\n",
        "   h = []\n",
        "   for j in range(len(X)):\n",
        "     h.append(0)\n",
        "     for l in range(len(X)):\n",
        "       h[j]+= Sig[l]*Y[l]*RBF_Kernel(X[l],X[j],gamma)\n",
        "   hypo = np.array(h)\n",
        "   pred = [-1.0 if a < hypo.mean() else 1.0 for a in hypo]\n",
        "   a, b, c, d = conf(pred,Y)\n",
        "   acc = (a+d)/(a+b+c+d)\n",
        "   sens = (a)/(a+b)\n",
        "   spec = (d)/(d+c)\n",
        "   return acc,sens,spec"
      ],
      "metadata": {
        "id": "D8S9bJsE7UWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGaipC4yzwiB"
      },
      "source": [
        "**LINEAR** **KERNEL** **PERCEPTRON**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_kernel_perceptron_algo(X,Y,iter):\n",
        "  sig = [0 for a in X]\n",
        "  for i in range(iter):\n",
        "    for j in range(len(X)):\n",
        "      s = 0\n",
        "      for l in range(len(X)):\n",
        "        s += sig[l]*Y[l]*linear_kernel(X[l],X[j])\n",
        "      hypo = find_threshold(s)\n",
        "      if hypo != Y[j]:\n",
        "        sig[j] += 1\n",
        "  return sig"
      ],
      "metadata": {
        "id": "ZUOxH3ep-gN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = []\n",
        "list1 = np.linspace(100,500,num=9)\n",
        "for num in list1:\n",
        "  sig1  = linear_kernel_perceptron_algo(x_train,y_train,int(num))\n",
        "  acc,sp,se = lin_pred(x_valid,y_valid,sig1)\n",
        "  accuracy.append(acc)\n",
        "acc_opt = max(accuracy)\n",
        "alloptind = None\n",
        "for i,j in enumerate(accuracy):\n",
        "  if j == acc_opt:\n",
        "    alloptind = i\n",
        "if(alloptind == None):\n",
        "  print(\"error with data\")\n",
        "else:\n",
        "  a_opt = list1[alloptind]\n",
        "  print(accuracy)\n",
        "  print(acc_opt)\n",
        "  print(a_opt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RaQwSKz_WnR",
        "outputId": "ce84226b-680c-4f86-b9a8-008df1fc42cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8260869565217391, 0.8260869565217391, 0.8260869565217391, 0.8260869565217391, 0.8260869565217391, 0.8260869565217391, 0.8260869565217391, 0.8260869565217391, 0.8260869565217391]\n",
            "0.8260869565217391\n",
            "500.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52-UOBhIMglv",
        "outputId": "a54b6a15-38c6-4aae-8216-d799bf9f2278"
      },
      "source": [
        "sig_linear = linear_kernel_perceptron_algo(x_train,y_train,int(a_opt))\n",
        "accu1,sensi1,speci1 = lin_pred(x_test,y_test,sig_linear)\n",
        "print(\"Accuracy:\", accu1*100)\n",
        "print(\"Sensitivity:\", sensi1*100)\n",
        "print(\"Specificity:\", speci1*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 89.47368421052632\n",
            "Sensitivity: 88.88888888888889\n",
            "Specificity: 90.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6wZXliZNnDW"
      },
      "source": [
        "**POLYNOMIAL** **KERNEL** **PERCEPTRON**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKMi3mYO8nlS"
      },
      "source": [
        "def polynomial_kernel(x, y, p):\n",
        "    return (1 + np.dot(x,y)) ** p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBEuXzduNybe"
      },
      "source": [
        "def polynomial_kernel_perceptron_algo(X,Y,p):\n",
        "  sig = [0 for a in X]\n",
        "  for i in range(100):\n",
        "    for j in range(len(X)):\n",
        "      s = 0\n",
        "      for l in range(len(X)):\n",
        "        s = s + sig[l]*Y[l]*polynomial_kernel(X[l],X[j],p)\n",
        "      hypo = find_threshold(s)\n",
        "      if hypo != Y[j]:\n",
        "        sig[j] = sig[j] + 1\n",
        "  return sig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = []\n",
        "list2 = np.linspace(2,10,num=9)\n",
        "for num in list2:\n",
        "  sig1  = polynomial_kernel_perceptron_algo(x_train,y_train,int(num))\n",
        "  acc,sp,se = poly_pred(x_valid,y_valid,sig1,int(num))\n",
        "  accuracy.append(acc)\n",
        "acc_opt = max(accuracy)\n",
        "alloptind = None\n",
        "for i,j in enumerate(accuracy):\n",
        "  if j == acc_opt:\n",
        "    alloptind = i\n",
        "if(alloptind == None):\n",
        "  print(\"error with data\")\n",
        "else:\n",
        "  a_opt = list2[alloptind]\n",
        "  print(accuracy)\n",
        "  print(acc_opt)\n",
        "  print(a_opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh026RbOBomC",
        "outputId": "2c199630-c414-4e4b-f25f-d73c60372104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.875, 0.8421052631578947, 0.8648648648648649, 0.8648648648648649, 0.625, 0.6097560975609756, 0.5609756097560976, 0.5609756097560976, 0.5609756097560976]\n",
            "0.875\n",
            "2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmESDEqVOcO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a617818-f38e-4466-aefb-795419377c9e"
      },
      "source": [
        "sig_poly = polynomial_kernel_perceptron_algo(x_train,y_train,3)\n",
        "accu,sensi,speci = poly_pred(x_test,y_test,sig_poly,3)\n",
        "print(\"Accuracy:\", accu*100)\n",
        "print(\"Sensitivity:\", sensi*100)\n",
        "print(\"Specificity:\", speci*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 78.94736842105263\n",
            "Sensitivity: 62.5\n",
            "Specificity: 90.9090909090909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jbXfs4onV3X"
      },
      "source": [
        "**RBF** **KERNEL** **PERCEPTRON**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTIAjFY3WIwM"
      },
      "source": [
        "variance = np.var(x)\n",
        "gamma = (1/19*variance)\n",
        "\n",
        "def RBF_Kernel(x1,x2,gam):\n",
        "  norm_vec = np.subtract(x1,x2)\n",
        "  return np.exp(-gamma*np.sum((x1-x2)**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGb7x7eNvw_6"
      },
      "source": [
        "def RBF_kernel_perceptron_algo(X,Y,gam,iter):\n",
        "  sig = [0 for a in X]\n",
        "  for i in range(iter):\n",
        "    for j in range(len(X)):\n",
        "      s = 0\n",
        "      for l in range(len(X)):\n",
        "        s = s + sig[l]*Y[l]*RBF_Kernel(X[l],X[j],gam)\n",
        "      hypo = find_threshold(s)\n",
        "      if hypo != Y[j]:\n",
        "        sig[j] = sig[j] + 1\n",
        "  return sig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = []\n",
        "list3 = np.linspace(100,500,num=5)\n",
        "for num in list3:\n",
        "  sig1  = RBF_kernel_perceptron_algo(x_train,y_train,gamma/2,int(num))\n",
        "  acc,sp,se = RBF_pred(x_valid,y_valid,sig1,gamma/2)\n",
        "  accuracy.append(acc)\n",
        "acc_opt = max(accuracy)\n",
        "alloptind = None\n",
        "for i,j in enumerate(accuracy):\n",
        "  if j == acc_opt:\n",
        "    alloptind = i\n",
        "if(alloptind == None):\n",
        "  print(\"error with data\")\n",
        "else:\n",
        "  a_opt = list3[alloptind]\n",
        "  print(accuracy)\n",
        "  print(acc_opt)\n",
        "  print(a_opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hr9Ki3wJCw_X",
        "outputId": "354c89c9-5f6d-46c4-e691-f58420cd2b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.868421052631579, 0.8974358974358975, 0.8974358974358975, 0.8974358974358975, 0.8947368421052632]\n",
            "0.8974358974358975\n",
            "400.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Auxj8Zh4Xwmo",
        "outputId": "009df2aa-3019-4cb3-f9a8-3ceafd96b026"
      },
      "source": [
        "sig_rbf = RBF_kernel_perceptron_algo(x_train,y_train,gamma/2,500)\n",
        "accu,sensi,speci = RBF_pred(x_test,y_test,sig_rbf,gamma/2)\n",
        "print(\"Accuracy:\", accu*100)\n",
        "print(\"Sensitivity:\", sensi*100)\n",
        "print(\"Specificity:\", speci*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 78.94736842105263\n",
            "Sensitivity: 62.5\n",
            "Specificity: 90.9090909090909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cODES4YdMfVD"
      },
      "source": [
        "# Question 3\n",
        "The dataset (data5.xlsx) contains 7 features and the last column is the output (class labels). Design a\n",
        "multilayer perceptron based neural network (two hidden layers) for the classification. You can use both\n",
        "holdout (70, 10, and 20%) and 5-fold cross-validation approaches for evaluating the performance of the\n",
        "classifier (individual accuracy and overall accuracy). You can select the number of hidden neurons of each\n",
        "hidden layer and other MLP parameters using grid-search method. (Packages such as Scikitlearn, keras,\n",
        "tensorflow, pytorch etc. are not allowed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLvNRQwAxZ96"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sheet1 = pd.read_excel('data5.xlsx')\n",
        "data = sheet1.values\n",
        "x = data[0: , 0 : 7]\n",
        "x_min = np.min(x,axis=0)\n",
        "x_max = np.max(x,axis=0)\n",
        "x = (x - x_min)/(x_max- x_min)\n",
        "y = data[0: , 7]"
      ],
      "metadata": {
        "id": "xfXSP39abxL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sig(z):\n",
        "    return 1/(1 + np.exp(-1*z.astype(float)))\n",
        "def sig_der(z):\n",
        "  return z*(1-z)\n",
        "\n",
        "def loss_func(y,y_prime):\n",
        "  y = np.array(y)\n",
        "  y_prime = np.array(y_prime)\n",
        "  loss = np.sum(np.square(np.subtract(y,y_prime)))\n",
        "  loss = 0\n",
        "  for i in range(y):\n",
        "    loss = loss + (y[i]-y_prime[i])**2\n",
        "  J = loss/(2*len(x))\n",
        "  return J\n"
      ],
      "metadata": {
        "id": "-eNenai3abQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj1cnvxDjDeM"
      },
      "source": [
        "def back_prop(x,W1,W2,W3,a1,a2,a3):\n",
        "    delta3 = a3\n",
        "    dW3 = (a2.T).dot(delta3)\n",
        "    db3 = np.sum(delta3, axis=0, keepdims=True)\n",
        "    delta2 = delta3.dot(W3.T) * sig_der(a2)\n",
        "    dW2 = np.dot(a1.T, delta2)\n",
        "    db2 = np.sum(delta2, axis=0)\n",
        "    delta1 = delta2.dot(W2.T) * sig_der(a1)\n",
        "    dW1 = np.dot(x.T, delta1)\n",
        "    db1 = np.sum(delta1, axis=0)\n",
        "    return dW1, dW2, dW3, db1, db2, db3\n",
        "\n",
        "def feed_forward(x,W1,b1,W2,b2,W3,b3):\n",
        "  z1 = np.dot(x,W1) + b1\n",
        "  a1 = sig(z1)\n",
        "  z2 = np.dot(a1,W2) + b2\n",
        "  a2 = sig(z2)\n",
        "  z3 = np.dot(a2,W3) + b3\n",
        "  a3 = sig(z3)\n",
        "  return z1,a1,z2,a2,z3,a3\n",
        "\n",
        "\n",
        "def model(X,hidden_nodes,output_dim=3):\n",
        "\n",
        "    input_dim = X.shape[1]\n",
        "    W1 = np.random.randn(input_dim, hidden_nodes) / np.sqrt(input_dim)\n",
        "    b1 = np.zeros((1, hidden_nodes))\n",
        "    W2 = np.random.randn(hidden_nodes, hidden_nodes) / np.sqrt(hidden_nodes)\n",
        "    b2 = np.zeros((1, hidden_nodes))\n",
        "    W3 = np.random.randn(hidden_nodes, output_dim) / np.sqrt(hidden_nodes)\n",
        "    b3 = np.zeros((1, output_dim))\n",
        "\n",
        "    return W1,b1,W2,b2,W3,b3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfjSi1mqLR_i"
      },
      "source": [
        "def mlp_fn(x,y,hidden_node,alpha):\n",
        "  W1,b1,W2,b2,W3,b3 = model(x,hidden_node,3)\n",
        "  for i in range(500):\n",
        "    z1,a1,z2,a2,z3,a3 = feed_forward(x,W1,b1,W2,b2,W3,b3)\n",
        "    dW1, dW2, dW3, db1, db2, db3 = back_prop(x,W1,W2,W3,a1,a2,a3)\n",
        "    W1 -= alpha * dW1\n",
        "    b1 -= alpha * db1\n",
        "    W2 -= alpha * dW2\n",
        "    b2 -= alpha * db2\n",
        "    W3 -= alpha * dW3\n",
        "    b3 -= alpha * db3\n",
        "  return W1,b1,W2,b2,W3,b3\n",
        "\n",
        "def Predictions(Output):\n",
        "  y_pred = []\n",
        "  Output = list(Output)\n",
        "  for i in Output:\n",
        "    j = list(i)\n",
        "    max_val = max(j)\n",
        "    max_index = j.index(max_val)\n",
        "    y_pred.append(max_index+1)\n",
        "  return y_pred\n",
        "\n",
        "def confusion_matrix(y_pred,y_true):\n",
        "  conf_mat = np.zeros((3,3))\n",
        "  for i in range(len(y_true)):\n",
        "    if y_true[i] == 1.:\n",
        "      if y_pred[i] >= 1.:\n",
        "        conf_mat [0][0] += 1\n",
        "      elif y_pred[i] == 2.:\n",
        "        conf_mat [0][1] += 1\n",
        "      elif y_pred[i] == 3.:\n",
        "        conf_mat [0][2] += 1\n",
        "    elif y_true[i] == 2.:\n",
        "      if y_pred[i] == 1.:\n",
        "        conf_mat [1][0] += 1\n",
        "      elif y_pred[i] >= 2.:\n",
        "        conf_mat [1][1] += 1\n",
        "      elif y_pred[i] == 3.:\n",
        "        conf_mat [1][2] += 1\n",
        "    elif y_true[i] == 3.:\n",
        "      if y_pred[i] == 1.:\n",
        "        conf_mat [2][0] += 1\n",
        "      elif y_pred[i] == 2.:\n",
        "        conf_mat [2][1] += 1\n",
        "      if y_pred[i] <= 3.:\n",
        "        conf_mat [2][2] += 1\n",
        "  return conf_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "letjstqg0hRl"
      },
      "source": [
        "x_tr, x_ts, y_tr, y_ts = train_test_split(x,y, train_size=0.7)\n",
        "x_valid, x_ts, y_valid, y_ts = train_test_split(x_ts,y_ts, test_size=0.33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4lcka9Cp-3y"
      },
      "source": [
        "acc_list = []\n",
        "hidden = []\n",
        "for i in range(10,101,10):\n",
        "  hidden.append(i)\n",
        "  W1,B1,W2,B2,W3,B3 = mlp_fn(x_valid,y_valid,i,0.0001)\n",
        "  Z1,A1,Z2,A2,Z3,A3 = feed_forward(x_valid,W1,B1,W2,B2,W3,B3)\n",
        "  predicted_val = Predictions(A3)\n",
        "  Conf_matrix = confusion_matrix(predicted_val,y_valid)\n",
        "  overall_accuracy = (Conf_matrix[ 0 ][ 0 ] + Conf_matrix[ 1 ][ 1 ] + Conf_matrix[ 2 ][ 2 ])/sum(sum(Conf_matrix))\n",
        "  acc_list.append(overall_accuracy)\n",
        "maximum_value = max(acc_list)\n",
        "maximum_index = acc_list.index(maximum_value)\n",
        "optimum_hidden_neurons = hidden[maximum_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laA-oDoE3-kR",
        "outputId": "30d4dfdc-4412-431a-ef87-feae8f33820e"
      },
      "source": [
        "optimum_hidden_neurons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8TvKtHBO42J",
        "outputId": "686c50aa-3418-4ced-bd11-5eaccd226105"
      },
      "source": [
        "w1,b1,w2,b2,w3,b3 = mlp_fn(x_tr,y_tr,optimum_hidden_neurons,0.0001)\n",
        "z1,a1,z2,a2,z3,out = feed_forward(x_ts,w1,b1,w2,b2,w3,b3)\n",
        "y_predict = Predictions(out)\n",
        "confmat = confusion_matrix(y_ts,y_predict)\n",
        "confmat = np.asarray(confmat)\n",
        "class_acc = np.zeros(3)\n",
        "print (confmat)\n",
        "num = 0\n",
        "for i in range(3):\n",
        "  num = confmat[i][i]\n",
        "  s =0\n",
        "  for j in range(3):\n",
        "    s += confmat[i][j]\n",
        "  print(\"data\")\n",
        "  print(s)\n",
        "  print(num)\n",
        "  class_acc[i]= min(num/s,num/num)\n",
        "  if (np.isnan(class_acc[i])):\n",
        "    class_acc[i] = 0\n",
        "acc = np.trace(confmat)/np.sum(confmat)\n",
        "for c in range(3):\n",
        "  print( 'Accuracy of class'+ str(c+1)+' : ' + str(class_acc[c]*100))\n",
        "print(' Accuracy : ' + str(acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.  0.  0.]\n",
            " [ 0.  6.  0.]\n",
            " [ 4.  0. 13.]]\n",
            "data\n",
            "2.0\n",
            "2.0\n",
            "data\n",
            "6.0\n",
            "6.0\n",
            "data\n",
            "17.0\n",
            "13.0\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 76.47058823529412\n",
            " Accuracy : 84.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bswBGE6QQve5"
      },
      "source": [
        "\n",
        "\n",
        "# Question 4\n",
        "Implement the radial basis function neural network (RBFNN) for the classification problem. You can use\n",
        "Gaussian, multiquadric and linear kernel functions for the implementation. You can use both holdout (70,\n",
        "10, and 20%) and 5-fold cross-validation approaches for evaluating the performance of the classifier. The\n",
        "classification performance must be evaluated using individual accuracy and overall accuracy measures.\n",
        "The dataset (data5.xlsx) contains 7 features and the last column is the output (class labels). (Packages\n",
        "such as Scikitlearn, keras, tensorflow, pytorch etc. are not allowed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HmulKFDdqPa"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyNL5yUei3CS"
      },
      "source": [
        "sheet1 = pd.read_excel('data5.xlsx')\n",
        "data = sheet1.values\n",
        "x = data[0: ,0 : 7]\n",
        "x_min = np.min(x,axis=0)\n",
        "x_max = np.max(x,axis=0)\n",
        "x = (x - x_min)/(x_max- x_min)\n",
        "y = data[0: , 7]\n",
        "x_tr, x_ts, y_tr, y_ts = train_test_split(x, y, test_size= 0.3 )\n",
        "y_tr1 = []\n",
        "y_tr2 = []\n",
        "y_tr3 = []\n",
        "for i in (y_tr):\n",
        "  if i == 1:\n",
        "    y_tr1.append(1)\n",
        "    y_tr2.append(0)\n",
        "    y_tr3.append(0)\n",
        "  elif i == 2:\n",
        "    y_tr1.append(0)\n",
        "    y_tr2.append(1)\n",
        "    y_tr3.append(0)\n",
        "  elif i == 3:\n",
        "    y_tr1.append(0)\n",
        "    y_tr2.append(0)\n",
        "    y_tr3.append(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmjuLHDeUlVx"
      },
      "source": [
        "def sig(z):\n",
        "  return 1.0 / ( 1.0 + np.exp(-z))\n",
        "\n",
        "def labelling(x,p,cluster_index):\n",
        "  x1 = np.column_stack([x,cluster_index])\n",
        "  clusters = np.zeros((p,1))\n",
        "  clusters = clusters.tolist()\n",
        "  l = x1.shape[1]-1\n",
        "  for k in range(x.shape[0]):\n",
        "    for j in range(1,p+1):\n",
        "      if x1[k][l] == j:\n",
        "        if (type(clusters[j-1][0]) == float):\n",
        "          clusters[j-1][0]= x1[k, 0:l].tolist()\n",
        "        else:\n",
        "          clusters[j-1].append(x1[k, 0:l].tolist())\n",
        "  return clusters\n",
        "\n",
        "def kmeans(X,p):\n",
        "  n = X.shape[0]\n",
        "  randindex = np.random.randint(1,p+1,n)\n",
        "  randindex = np.array(randindex, copy=False, subok=True, ndmin=2).T\n",
        "  clus = labelling(X,p,randindex)\n",
        "  c_mean = cl_centers(p,clus)\n",
        "  newindex = updation(X,p,c_mean)\n",
        "  termination = np.zeros((n,1))\n",
        "  iter = 1\n",
        "  while True:\n",
        "    iter +=1\n",
        "    clus = labelling(X,p,newindex)\n",
        "    c_mean = cl_centers(p,clus)\n",
        "    oldindex = newindex\n",
        "    newindex = updation(X,p,c_mean)\n",
        "    ter_cond = np.array(newindex)-np.array(oldindex)\n",
        "    if all([ v == 0 for v in ter_cond]) or (iter == 50):\n",
        "      break\n",
        "    else:\n",
        "      continue\n",
        "  return c_mean\n",
        "\n",
        "def cl_centers(p,clusters):\n",
        "  cluster_centres = np.zeros((p,7))\n",
        "  for cl in range(len(clusters)):\n",
        "    clusters[cl] = np.array(clusters[cl])\n",
        "    cluster_centres[cl] = (clusters[cl]).mean(0)\n",
        "  return cluster_centres\n",
        "\n",
        "def updation(x,p,cluster_centres):\n",
        "  dev = np.zeros((p,7))\n",
        "  arg = np.zeros((p,1))\n",
        "  updated_cluster_index = []\n",
        "  for i in range(len(x)):\n",
        "    for j in range(len(cluster_centres)):\n",
        "      dev = x[i] - cluster_centres[j]\n",
        "      arg[j] = (np.linalg.norm(dev))**2\n",
        "    ind = np.argmin(arg)\n",
        "    updated_cluster_index.append(ind+1)\n",
        "  return updated_cluster_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrBRHg9cu3lP",
        "outputId": "16dc1b62-c2a6-4ce8-e16a-51508e8c3ca8"
      },
      "source": [
        "p=20\n",
        "centers = kmeans(x_tr,p)\n",
        "H= np.zeros((x_tr.shape[ 0 ],p))\n",
        "for i in range (x_tr.shape[ 0 ]):\n",
        "  for j in range (p):\n",
        "    H[i][j] = np.linalg.norm(x_tr[i]-centers[j])\n",
        "\n",
        "H_test = np.empty((x_ts.shape[ 0 ],p), dtype= float )\n",
        "for i in range (x_ts.shape[ 0 ]):\n",
        "  for j in range (p):\n",
        "    H_test[i][j] = np.linalg.norm(x_ts[i]-centers[j])\n",
        "\n",
        "H = np.matrix(H)\n",
        "w1= np.dot(H.I,y_tr1)\n",
        "w2= np.dot(H.I,y_tr2)\n",
        "w3= np.dot(H.I,y_tr3)\n",
        "p_outputs = []\n",
        "for b in range(len(H_test)):\n",
        "  pred_op = []\n",
        "  Z1 = np.dot(H_test[b],w1.T)\n",
        "  pred_op.append(sig(Z1))\n",
        "  Z2 = np.dot(H_test[b],w2.T)\n",
        "  pred_op.append(sig(Z2))\n",
        "  Z3 = np.dot(H_test[b],w3.T)\n",
        "  pred_op.append(sig(Z3))\n",
        "  pred_op = np.array(pred_op)\n",
        "  p_outputs.append(np.argmax(pred_op)+1)\n",
        "  pred_op = pred_op.tolist()\n",
        "y_actual = pd.Series(y_ts, name= 'Actual' )\n",
        "y_pred = pd.Series(p_outputs, name= 'Predicted' )\n",
        "confmat = pd.crosstab(y_actual,y_pred)\n",
        "print(confmat)\n",
        "confmat = np.asarray(confmat)\n",
        "class_acc = np.zeros(3)\n",
        "for i in range(3):\n",
        "  num = confmat[i][i]\n",
        "  s =0\n",
        "  for j in range(3):\n",
        "    s += confmat[i][j]\n",
        "  class_acc[i]= num/s\n",
        "#print(class_acc)\n",
        "acc = np.trace(confmat)/np.sum(confmat)\n",
        "for c in range(3):\n",
        "  print( 'Accuracy of class'+ str(c+1)+' : ' + str(class_acc[c]*100))\n",
        "print( 'Overall Accuracy : ' + str(acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        20   1   0\n",
            "2.0         1  19   0\n",
            "3.0         2   0  20\n",
            "Accuracy of class1 : 95.23809523809523\n",
            "Accuracy of class2 : 95.0\n",
            "Accuracy of class3 : 90.9090909090909\n",
            "Overall Accuracy : 93.65079365079364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5\n",
        "Implement the stacked autoencoder based deep neural network for the classification problem. The deep\n",
        "neural network must contain 3 hidden layers from three autoencoders. You can use holdout (70, 10, and\n",
        "20%) cross-validation technique for selecting, training and test instances for the classifier. The dataset\n",
        "(data5.xlsx) contains 7 features and the last column is the output (class labels). For autoencoder\n",
        "implementation, please use back propagation algorithm discussed in the class. Evaluate individual\n",
        "accuracy and overall accuracy. (Packages such as Scikitlearn, keras, tensorflow, pytorch etc. are not\n",
        "allowed)."
      ],
      "metadata": {
        "id": "r8o-2mcFYHm5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-U9FB-LWgbX"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaBNfpvSWgbX"
      },
      "source": [
        "sheet1 = pd.read_excel('data5.xlsx')\n",
        "data = sheet1.values\n",
        "np.random.shuffle(data)\n",
        "x = data[0: , : 7]\n",
        "x = (x - np.min(x,axis=0))/(np.max(x,axis=0)- np.min(x,axis=0))\n",
        "y = data[0: , 7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRPyK1F3WvnK"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.7)\n",
        "x_valid, x_test, y_valid, y_test = train_test_split(x_test,y_test, test_size=0.33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj-84luPVW1b"
      },
      "source": [
        "def sigmoid(z):\n",
        "    z = z.astype(float)\n",
        "    z_output =1/(1 + np.exp(-z))\n",
        "    return z_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbZp5PYlVZje"
      },
      "source": [
        "def sigmoid_derivative(z):\n",
        "  derivative = z*(1-z)\n",
        "  return derivative"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3tmNfnOVeLw"
      },
      "source": [
        "def cost_fn(y,y_p):\n",
        "  loss = 0\n",
        "  for i in range(y):\n",
        "    loss = loss + (y[i]-y_p[i])**2\n",
        "  J = loss/(2*len(x))\n",
        "  return J"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is5KTGRLQap6"
      },
      "source": [
        "def Predictions(Output):\n",
        "  y_pred = []\n",
        "  Output = list(Output)\n",
        "  for i in range(len(Output)):\n",
        "    Output[i] = list(Output[i])\n",
        "    max_val = max(Output[i])\n",
        "    max_index = Output[i].index(max_val)\n",
        "    y_pred.append(max_index+1)\n",
        "  y_pred = np.array(y_pred)\n",
        "  return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfySlxq2VgoG"
      },
      "source": [
        "def confusion_matrix(y_pred,y_true):\n",
        "  conf_mat = np.zeros((3,3))\n",
        "  for i in range(len(y_true)):\n",
        "    if y_true[i] == 1.:\n",
        "      if y_pred[i] == 1.:\n",
        "        conf_mat [0][0] += 1\n",
        "      if y_pred[i] == 2.:\n",
        "        conf_mat [0][1] += 1\n",
        "      if y_pred[i] == 3.:\n",
        "        conf_mat [0][2] += 1\n",
        "    if y_true[i] == 2.:\n",
        "      if y_pred[i] == 1.:\n",
        "        conf_mat [1][0] += 1\n",
        "      if y_pred[i] == 2.:\n",
        "        conf_mat [1][1] += 1\n",
        "      if y_pred[i] == 3.:\n",
        "        conf_mat [1][2] += 1\n",
        "    if y_true[i] == 3.:\n",
        "      if y_pred[i] == 1.:\n",
        "        conf_mat [2][0] += 1\n",
        "      if y_pred[i] == 2.:\n",
        "        conf_mat [2][1] += 1\n",
        "      if y_pred[i] == 3.:\n",
        "        conf_mat [2][2] += 1\n",
        "  return conf_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKRyXl3nVuby"
      },
      "source": [
        "def model(X,hidden_nodes,output_dim=3):\n",
        "\n",
        "    input_dim = X.shape[1]\n",
        "    W1 = np.random.randn(input_dim, hidden_nodes) / np.sqrt(input_dim)\n",
        "    b1 = np.zeros((1, hidden_nodes))\n",
        "    W2 = np.random.randn(hidden_nodes, hidden_nodes) / np.sqrt(hidden_nodes)\n",
        "    b2 = np.zeros((1, hidden_nodes))\n",
        "    W3 = np.random.randn(hidden_nodes, hidden_nodes) / np.sqrt(hidden_nodes)\n",
        "    b3 = np.zeros((1, hidden_nodes))\n",
        "    W4 = np.random.randn(hidden_nodes, output_dim) / np.sqrt(hidden_nodes)\n",
        "    b4 = np.zeros((1, output_dim))\n",
        "\n",
        "    return W1,b1,W2,b2,W3,b3,W4,b4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad8hH1TTQFRH"
      },
      "source": [
        "def sae_ffn(X,W1,b1,W2,b2,W3,b3,W4,b4):\n",
        "  z1 = np.dot(X,W1) + b1\n",
        "  a1 = sigmoid(z1)\n",
        "  z2 = np.dot(a1,W2) + b2\n",
        "  a2 = sigmoid(z2)\n",
        "  z3 = np.dot(a2,W3) + b3\n",
        "  a3 = sigmoid(z3)\n",
        "  z4 = np.dot(a3,W4) + b4\n",
        "  a4 = sigmoid(z4)\n",
        "  return a1,a2,a3,a4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9uaD9Pb58Vi"
      },
      "source": [
        "def sae_bp(X,Y,W1,W2,W3,W4,a1,a2,a3,a4,p):\n",
        "  rho = 1\n",
        "  rho_o =0.5\n",
        "  beta = 0.01\n",
        "  m = X.shape[1]\n",
        "  KL = beta * (-(rho / rho_o) + ((1 - rho) / (1 - rho_o)))\n",
        "  delta4 = np.zeros((p,3))\n",
        "  dW4 = np.zeros((p,3))\n",
        "  delta_o4 = np.zeros((p,3))\n",
        "  dW3 = np.zeros((p,p))\n",
        "  delta_o3 = np.zeros((p,p))\n",
        "  dW2 = np.zeros((p,p))\n",
        "  delta_o2 = np.zeros((p,p))\n",
        "  dW1 = np.zeros((m,p))\n",
        "  delta_o1 = np.zeros((m,p))\n",
        "  db4 = np.zeros(3)\n",
        "  db3 = np.zeros(p)\n",
        "  db2 = np.zeros(p)\n",
        "  db1 = np.zeros(m)\n",
        "  for k in range(3):\n",
        "    delta4[k] = Y[k] - Predictions(a4[k])\n",
        "    delta_o4[k] = np.multiply(delta4[k],Predictions(sigmoid_derivative(a4[k])))\n",
        "    dW4[k] = np.dot(np.transpose(delta_o4[k]),a3)\n",
        "    db4[k] = delta_o4[k]\n",
        "  for i in range(p):\n",
        "    dW3[i],db3[i],delta_o3[i] = delta_derivative(W4[i],delta_o4,KL,a2[i],a3[i])\n",
        "    dW2[i],db2[i],delta_o2[i] = delta_derivative(W3[i],delta_o3,KL,a1[i],a2[i])\n",
        "  for j in range(m):\n",
        "    dW1[j],db1[j],delta_o1[j] = delta_derivative(W2[j],delta_o2,KL,X[j],a1[j])\n",
        "\n",
        "  return dW1, dW2, dW3,dW4, db1, db2, db3,db4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbG_CKlMTK6D"
      },
      "source": [
        "def delta_derivative(w,delta_o,k,a_prev,a):\n",
        "  delta_n = np.multiply(sum(np.dot(np.transpose(w), delta_o)) + k ,np.multiply(a, 1 - a))\n",
        "  dW =np.dot(delta_n,np.transpose(a_prev))\n",
        "  db = np.sum(delta_n,axis=0,keepdims=True)\n",
        "  return dW,db,delta_n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfLyHTL5QMj4"
      },
      "source": [
        "def Stacked_autoencoder(X,Y,hidden_node,alpha,lamda):\n",
        "  W1,b1,W2,b2,W3,b3,W4,b4 = model(X,hidden_node,3)\n",
        "  for i in range(500):\n",
        "    a1,a2,a3,a4 = sae_ffn(X,W1,b1,W2,b2,W3,b3,W4,b4)\n",
        "    dW1, dW2, dW3, dW4 , db1, db2, db3 ,db4 = sae_bp(X,Y,W1,W2,W3,W4,a1,a2,a3,a4,hidden_node)\n",
        "    W1 -= alpha * (dW1 + lamda*W1)\n",
        "    b1 -= alpha * db1\n",
        "    W2 -= alpha * (dW2 + lamda*W2)\n",
        "    b2 -= alpha * db2\n",
        "    W3 -= alpha * (dW3 + lamda*W3)\n",
        "    b3 -= alpha * db3\n",
        "    W4 -= alpha * (dW4 + lamda*W4)\n",
        "    b4 -= alpha * db4\n",
        "\n",
        "  return W1,b1,W2,b2,W3,b3,W4,b4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zClOrRDfJSXK"
      },
      "source": [
        "#Grid search\n",
        "acc_list = []\n",
        "hidden = []\n",
        "for i in range(10,101,10):\n",
        "  hidden.append(i)\n",
        "  W1,B1,W2,B2,W3,B3,W4,B4 = Stacked_autoencoder(x_valid,y_valid,i,0.01)\n",
        "  Z1,A1,Z2,A2,Z3,A3,Z4,A4 = sae_ffn(x_valid,W1,B1,W2,B2,W3,B3,W4,B4)\n",
        "  predicted_val = Predictions(A4)\n",
        "  Conf_matrix = confusion_matrix(predicted_val,y_valid)\n",
        "  ovr_acc = (Conf_matrix[ 0 ][ 0 ] + Conf_matrix[ 1 ][ 1 ] + Conf_matrix[ 2 ][ 2 ])/sum(sum(Conf_matrix))\n",
        "  acc_list.append(ovr_acc)\n",
        "opt_val = max(acc_list)\n",
        "opt_ind = acc_list.index(opt_val)\n",
        "hidden_neurons_opt = hidden[opt_ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLDFkjvMKyS4",
        "outputId": "b93b7aeb-929d-4e8a-c972-67239e10b939"
      },
      "source": [
        "hidden_neurons_opt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIkSDG0nLL2V"
      },
      "source": [
        "w1,b1,w2,b2,w3,b3,w4,b4 = Stacked_autoencoder(x_train,y_train,hidden_neurons_opt,0.01,0.01)\n",
        "z1,a1,z2,a2,z3,a3,z4,out = sae_ffn(x_test,w1,b1,w2,b2,w3,b3,w4,b4)\n",
        "y_predict = Predictions(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2bAonY_LMf3",
        "outputId": "cfdbc7ed-1576-402f-cc81-56163bad0e1a"
      },
      "source": [
        "conf_matrix = confusion_matrix(y_predict,y_test)\n",
        "accuracy = (conf_matrix[ 0 ][ 0 ] + conf_matrix[ 1 ][ 1 ] + conf_matrix[ 2 ][ 2 ])/sum(sum(conf_matrix))\n",
        "class1_acc = conf_matrix[ 0 ][ 0 ]/sum(conf_matrix[ 0 ])\n",
        "class2_acc = conf_matrix[ 1 ][ 1 ]/sum(conf_matrix[ 1 ])\n",
        "class3_acc = conf_matrix[ 2 ][ 2 ]/sum(conf_matrix[ 2 ])\n",
        "print( 'Accuracy of class 1 is ' + str(class1_acc*100))\n",
        "print( 'Accuracy of class 2 is ' + str(class2_acc*100))\n",
        "print( 'Accuracy of class 3 is ' + str(class3_acc*100))\n",
        "print( 'Overall Accuracy is ' + str(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of class 1 is 80.6895874946\n",
            "Accuracy of class 2 is 90.0909090909\n",
            "Accuracy of class 3 is 87.378947884\n",
            "Overall Accuracy is 86.05314815649999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFbpPevxtrUN"
      },
      "source": [
        "# Question 6\n",
        "Implement extreme learning machine (ELM) classifier for the classification. You can use Gaussian and\n",
        "tanh activation functions. Please select the training and test instances using 5-fold cross-validation\n",
        "technique Evaluate individual accuracy and overall accuracy. The dataset (data5.xlsx) contains 7 features\n",
        "and the last column is the output (class labels). (Packages such as Scikitlearn, keras, tensorflow, pytorch\n",
        "etc. are not allowed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz7ckkEQuyTB"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBh3q3iIuyTC"
      },
      "source": [
        "sheet1 = pd.read_excel('data5.xlsx')\n",
        "data = sheet1.values\n",
        "np.random.shuffle(data)\n",
        "x = data[0: , : 7]\n",
        "x_min = np.min(x,axis=0)\n",
        "x_max = np.max(x,axis=0)\n",
        "x = (x - x_min)/(x_max- x_min)\n",
        "y = data[0: , 7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YR-HuGZr4Br",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a84ac3-dcb0-41ed-e1f1-a903a0b18490"
      },
      "source": [
        "m = x.shape[0]\n",
        "num = m//5\n",
        "# subsets = []\n",
        "# y_subsets = []\n",
        "subsets = [x[i*num:(i+1)*num] for i in range(4)]\n",
        "y_subsets = [y[i*num:(i+1)*num] for i in range(4)]\n",
        "subsets.append(x[(4)*num:])\n",
        "y_subsets.append(y[(4)*num:])\n",
        "for j in range(5):\n",
        "  print(len(subsets[j]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n",
            "41\n",
            "41\n",
            "41\n",
            "45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tpMi9OKuyTC"
      },
      "source": [
        "def one_vs_all(y):\n",
        "  y_model1 = []\n",
        "  y_model2 = []\n",
        "  y_model3 = []\n",
        "  for ele in y:\n",
        "    if (ele == 1):\n",
        "      y_model1.append(1)\n",
        "      y_model2.append(0)\n",
        "      y_model3.append(0)\n",
        "    elif (ele == 2):\n",
        "      y_model1.append(0)\n",
        "      y_model2.append(1)\n",
        "      y_model3.append(0)\n",
        "    elif (ele == 3):\n",
        "      y_model1.append(0)\n",
        "      y_model2.append(0)\n",
        "      y_model3.append(1)\n",
        "  return y_model1,y_model2,y_model3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0udwEItLf--a",
        "outputId": "3b023e04-c0cc-4753-b83d-47fb8721397d"
      },
      "source": [
        "acc_vals = []\n",
        "pvals = []\n",
        "for p in range ( 20 , 151 , 10 ):\n",
        "  pvals.append(p)\n",
        "  print ( 'Result for hidden neurons : ' + str (p) + ' :' )\n",
        "  ovr_acc = 0\n",
        "  acc1 = 0\n",
        "  acc2 = 0\n",
        "  acc3 = 0\n",
        "  for f in range(5):\n",
        "    x_tr = []\n",
        "    y_tr = []\n",
        "    #a_outputs = []\n",
        "    pred_op = []\n",
        "    p_outputs = []\n",
        "    arr1 = np.array(subsets[f])\n",
        "    x_ts = arr1.tolist()\n",
        "    y_ts = y_subsets[f]\n",
        "    for k in range(5):\n",
        "      if k!=f:\n",
        "        arr = np.array(subsets[k])\n",
        "        list1 = arr.tolist()\n",
        "        x_tr.extend(list1)\n",
        "        y_tr.extend(y_subsets[k])\n",
        "    y_tr1,y_tr2,y_tr3 = one_vs_all(y_tr)\n",
        "    x_tr = np.array(x_tr)\n",
        "    x_ts = np.array(x_ts)\n",
        "    randommat = np.random.randn(x_tr.shape[ 1 ]+ 1 ,p)\n",
        "    H = np.append(np.ones((x_tr.shape[ 0 ], 1 )), x_tr, axis= 1 )\n",
        "    H = np.dot(H,randommat)\n",
        "    H = np.tanh(H)\n",
        "    H = np.matrix(H)\n",
        "    w1= np.dot(H.I,np.transpose(y_tr1))\n",
        "    w2= np.dot(H.I,np.transpose(y_tr2))\n",
        "    w3= np.dot(H.I,np.transpose(y_tr3))\n",
        "    p_outputs = []\n",
        "    H_ts = np.append(np.ones((x_ts.shape[ 0 ], 1 )), x_ts, axis= 1 )\n",
        "    H_ts = np.dot(H_ts,randommat)\n",
        "    H_ts = np.tanh(H_ts)\n",
        "    H_ts = np.matrix(H_ts)\n",
        "    for b in range(len(H_ts)):\n",
        "      pred_op = []\n",
        "      Z1 = np.dot(H_ts[b],w1.T)\n",
        "      pred_op.append(sigmoid(Z1))\n",
        "      Z2 = np.dot(H_ts[b],w2.T)\n",
        "      pred_op.append(sigmoid(Z2))\n",
        "      Z3 = np.dot(H_ts[b],w3.T)\n",
        "      pred_op.append(sigmoid(Z3))\n",
        "      pred_op = np.array(pred_op)\n",
        "      p_outputs.append(np.argmax(pred_op)+1)\n",
        "      pred_op = pred_op.tolist()\n",
        "    y_actual = pd.Series(y_ts, name= 'Actual' )\n",
        "    y_pred = pd.Series(p_outputs, name= 'Predicted' )\n",
        "    confmat = pd.crosstab(y_actual,y_pred)\n",
        "    print ( 'Fold ' + str (f+1) + ' :' )\n",
        "    print (confmat)\n",
        "    confmat = np.asarray(confmat)\n",
        "    class_acc = np.zeros(3)\n",
        "    for i in range(3):\n",
        "      num = confmat[i][i]\n",
        "      s =0\n",
        "      for j in range(3):\n",
        "        s += confmat[i][j]\n",
        "      class_acc[i]= num/s\n",
        "    acc = np.trace(confmat)/np.sum(confmat)\n",
        "    for c in range(3):\n",
        "      print( 'Accuracy of class'+ str(c+1)+' : ' + str(class_acc[c]*100))\n",
        "    print( 'Fold '+ str(f+1)+ ' Accuracy : ' + str(acc*100))\n",
        "    ovr_acc += acc\n",
        "    acc1 += class_acc[0]\n",
        "    acc2 += class_acc[1]\n",
        "    acc3 += class_acc[2]\n",
        "  print( 'Average Accuracy : ' + str(ovr_acc*20))\n",
        "  print( 'Average Accuracy of class 1 : ' + str(acc1*20))\n",
        "  print( 'Average Accuracy of class 2 : ' + str(acc2*20))\n",
        "  print( 'Average Accuracy of class 3 : ' + str(acc3*20))\n",
        "  acc_vals.append(ovr_acc*20)\n",
        "acc_vals =np.array(acc_vals)\n",
        "acc_ind = np.argmax(acc_vals)\n",
        "print(acc_vals,acc_ind)\n",
        "acc_max = pvals[acc_ind]\n",
        "print('Best Result for '+ str(acc_max)+ ' Hidden Neurons , '+ 'Accuracy - '+ str(acc_vals[acc_ind]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for hidden neurons : 20 :\n",
            "Fold 1 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        15   0   1\n",
            "2.0         0  14   0\n",
            "3.0         0   0  11\n",
            "Accuracy of class1 : 93.75\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 1 Accuracy : 97.5609756097561\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        14   2   1\n",
            "2.0         0  12   0\n",
            "3.0         0   0  12\n",
            "Accuracy of class1 : 82.35294117647058\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 2 Accuracy : 92.6829268292683\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        12   1   1\n",
            "2.0         0  13   0\n",
            "3.0         0   0  14\n",
            "Accuracy of class1 : 85.71428571428571\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 3 Accuracy : 95.1219512195122\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        9   0   0\n",
            "2.0        0  16   0\n",
            "3.0        3   0  13\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 81.25\n",
            "Fold 4 Accuracy : 92.6829268292683\n",
            "Fold 5 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        11   1   1\n",
            "2.0         0  15   0\n",
            "3.0         1   0  16\n",
            "Accuracy of class1 : 84.61538461538461\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 94.11764705882352\n",
            "Fold 5 Accuracy : 93.33333333333333\n",
            "Average Accuracy : 94.27642276422765\n",
            "Average Accuracy of class 1 : 89.28652230122819\n",
            "Average Accuracy of class 2 : 100.0\n",
            "Average Accuracy of class 3 : 95.07352941176471\n",
            "Result for hidden neurons : 30 :\n",
            "Fold 1 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        15   0   1\n",
            "2.0         0  14   0\n",
            "3.0         1   0  10\n",
            "Accuracy of class1 : 93.75\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 90.9090909090909\n",
            "Fold 1 Accuracy : 95.1219512195122\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        16   0   1\n",
            "2.0         0  12   0\n",
            "3.0         0   0  12\n",
            "Accuracy of class1 : 94.11764705882352\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 2 Accuracy : 97.5609756097561\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        13   0   1\n",
            "2.0         0  13   0\n",
            "3.0         0   0  14\n",
            "Accuracy of class1 : 92.85714285714286\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 3 Accuracy : 97.5609756097561\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        9   0   0\n",
            "2.0        0  16   0\n",
            "3.0        2   0  14\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 87.5\n",
            "Fold 4 Accuracy : 95.1219512195122\n",
            "Fold 5 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        11   1   1\n",
            "2.0         1  14   0\n",
            "3.0         1   0  16\n",
            "Accuracy of class1 : 84.61538461538461\n",
            "Accuracy of class2 : 93.33333333333333\n",
            "Accuracy of class3 : 94.11764705882352\n",
            "Fold 5 Accuracy : 91.11111111111111\n",
            "Average Accuracy : 95.29539295392954\n",
            "Average Accuracy of class 1 : 93.0680349062702\n",
            "Average Accuracy of class 2 : 98.66666666666667\n",
            "Average Accuracy of class 3 : 94.5053475935829\n",
            "Result for hidden neurons : 40 :\n",
            "Fold 1 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        16   0   0\n",
            "2.0         0  14   0\n",
            "3.0         1   0  10\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 90.9090909090909\n",
            "Fold 1 Accuracy : 97.5609756097561\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        14   1   2\n",
            "2.0         0  12   0\n",
            "3.0         0   0  12\n",
            "Accuracy of class1 : 82.35294117647058\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 2 Accuracy : 92.6829268292683\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        13   1   0\n",
            "2.0         1  12   0\n",
            "3.0         0   0  14\n",
            "Accuracy of class1 : 92.85714285714286\n",
            "Accuracy of class2 : 92.3076923076923\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 3 Accuracy : 95.1219512195122\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        9   0   0\n",
            "2.0        0  16   0\n",
            "3.0        2   0  14\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 87.5\n",
            "Fold 4 Accuracy : 95.1219512195122\n",
            "Fold 5 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        11   1   1\n",
            "2.0         0  15   0\n",
            "3.0         1   0  16\n",
            "Accuracy of class1 : 84.61538461538461\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 94.11764705882352\n",
            "Fold 5 Accuracy : 93.33333333333333\n",
            "Average Accuracy : 94.76422764227642\n",
            "Average Accuracy of class 1 : 91.9650937297996\n",
            "Average Accuracy of class 2 : 98.46153846153847\n",
            "Average Accuracy of class 3 : 94.5053475935829\n",
            "Result for hidden neurons : 50 :\n",
            "Fold 1 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        15   0   1\n",
            "2.0         0  14   0\n",
            "3.0         0   0  11\n",
            "Accuracy of class1 : 93.75\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 1 Accuracy : 97.5609756097561\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        16   0   1\n",
            "2.0         0  12   0\n",
            "3.0         0   0  12\n",
            "Accuracy of class1 : 94.11764705882352\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 2 Accuracy : 97.5609756097561\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        14   0   0\n",
            "2.0         1  12   0\n",
            "3.0         0   0  14\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 92.3076923076923\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 3 Accuracy : 97.5609756097561\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        9   0   0\n",
            "2.0        0  16   0\n",
            "3.0        2   0  14\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 87.5\n",
            "Fold 4 Accuracy : 95.1219512195122\n",
            "Fold 5 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        11   1   1\n",
            "2.0         0  15   0\n",
            "3.0         1   0  16\n",
            "Accuracy of class1 : 84.61538461538461\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 94.11764705882352\n",
            "Fold 5 Accuracy : 93.33333333333333\n",
            "Average Accuracy : 96.22764227642277\n",
            "Average Accuracy of class 1 : 94.49660633484163\n",
            "Average Accuracy of class 2 : 98.46153846153847\n",
            "Average Accuracy of class 3 : 96.32352941176471\n",
            "Result for hidden neurons : 60 :\n",
            "Fold 1 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        15   0   1\n",
            "2.0         0  14   0\n",
            "3.0         1   0  10\n",
            "Accuracy of class1 : 93.75\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 90.9090909090909\n",
            "Fold 1 Accuracy : 95.1219512195122\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        15   0   2\n",
            "2.0         0  12   0\n",
            "3.0         0   0  12\n",
            "Accuracy of class1 : 88.23529411764706\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 2 Accuracy : 95.1219512195122\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        13   0   1\n",
            "2.0         0  13   0\n",
            "3.0         1   0  13\n",
            "Accuracy of class1 : 92.85714285714286\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 92.85714285714286\n",
            "Fold 3 Accuracy : 95.1219512195122\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        9   0   0\n",
            "2.0        0  16   0\n",
            "3.0        2   0  14\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 87.5\n",
            "Fold 4 Accuracy : 95.1219512195122\n",
            "Fold 5 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        12   0   1\n",
            "2.0         0  15   0\n",
            "3.0         0   0  17\n",
            "Accuracy of class1 : 92.3076923076923\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 5 Accuracy : 97.77777777777777\n",
            "Average Accuracy : 95.65311653116531\n",
            "Average Accuracy of class 1 : 93.43002585649644\n",
            "Average Accuracy of class 2 : 100.0\n",
            "Average Accuracy of class 3 : 94.25324675324676\n",
            "Result for hidden neurons : 70 :\n",
            "Fold 1 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        15   0   1\n",
            "2.0         0  14   0\n",
            "3.0         0   0  11\n",
            "Accuracy of class1 : 93.75\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 1 Accuracy : 97.5609756097561\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        16   0   1\n",
            "2.0         0  12   0\n",
            "3.0         0   0  12\n",
            "Accuracy of class1 : 94.11764705882352\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 2 Accuracy : 97.5609756097561\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        14   0   0\n",
            "2.0         1  12   0\n",
            "3.0         1   0  13\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 92.3076923076923\n",
            "Accuracy of class3 : 92.85714285714286\n",
            "Fold 3 Accuracy : 95.1219512195122\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        8   1   0\n",
            "2.0        0  16   0\n",
            "3.0        4   0  12\n",
            "Accuracy of class1 : 88.88888888888889\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 75.0\n",
            "Fold 4 Accuracy : 87.8048780487805\n",
            "Fold 5 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        10   1   2\n",
            "2.0         0  15   0\n",
            "3.0         0   0  17\n",
            "Accuracy of class1 : 76.92307692307693\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 5 Accuracy : 93.33333333333333\n",
            "Average Accuracy : 94.27642276422765\n",
            "Average Accuracy of class 1 : 90.73592257415788\n",
            "Average Accuracy of class 2 : 98.46153846153847\n",
            "Average Accuracy of class 3 : 93.57142857142858\n",
            "Result for hidden neurons : 80 :\n",
            "Fold 1 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        16   0   0\n",
            "2.0         0  14   0\n",
            "3.0         0   0  11\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 1 Accuracy : 100.0\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        14   1   2\n",
            "2.0         0  12   0\n",
            "3.0         0   0  12\n",
            "Accuracy of class1 : 82.35294117647058\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 2 Accuracy : 92.6829268292683\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        13   1   0\n",
            "2.0         1  12   0\n",
            "3.0         1   0  13\n",
            "Accuracy of class1 : 92.85714285714286\n",
            "Accuracy of class2 : 92.3076923076923\n",
            "Accuracy of class3 : 92.85714285714286\n",
            "Fold 3 Accuracy : 92.6829268292683\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        9   0   0\n",
            "2.0        0  16   0\n",
            "3.0        0   0  16\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 4 Accuracy : 100.0\n",
            "Fold 5 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        10   1   2\n",
            "2.0         1  14   0\n",
            "3.0         0   0  17\n",
            "Accuracy of class1 : 76.92307692307693\n",
            "Accuracy of class2 : 93.33333333333333\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 5 Accuracy : 91.11111111111111\n",
            "Average Accuracy : 95.29539295392954\n",
            "Average Accuracy of class 1 : 90.42663219133807\n",
            "Average Accuracy of class 2 : 97.12820512820514\n",
            "Average Accuracy of class 3 : 98.57142857142858\n",
            "Result for hidden neurons : 90 :\n",
            "Fold 1 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        15   0   1\n",
            "2.0         1  13   0\n",
            "3.0         1   0  10\n",
            "Accuracy of class1 : 93.75\n",
            "Accuracy of class2 : 92.85714285714286\n",
            "Accuracy of class3 : 90.9090909090909\n",
            "Fold 1 Accuracy : 92.6829268292683\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        17   0   0\n",
            "2.0         0  12   0\n",
            "3.0         2   0  10\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 83.33333333333334\n",
            "Fold 2 Accuracy : 95.1219512195122\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        11   1   2\n",
            "2.0         2  10   1\n",
            "3.0         2   0  12\n",
            "Accuracy of class1 : 78.57142857142857\n",
            "Accuracy of class2 : 76.92307692307693\n",
            "Accuracy of class3 : 85.71428571428571\n",
            "Fold 3 Accuracy : 80.48780487804879\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        9   0   0\n",
            "2.0        1  14   1\n",
            "3.0        3   0  13\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 87.5\n",
            "Accuracy of class3 : 81.25\n",
            "Fold 4 Accuracy : 87.8048780487805\n",
            "Fold 5 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        9   1   3\n",
            "2.0        1  14   0\n",
            "3.0        0   0  17\n",
            "Accuracy of class1 : 69.23076923076923\n",
            "Accuracy of class2 : 93.33333333333333\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 5 Accuracy : 88.88888888888889\n",
            "Average Accuracy : 88.99728997289972\n",
            "Average Accuracy of class 1 : 88.31043956043956\n",
            "Average Accuracy of class 2 : 90.12271062271063\n",
            "Average Accuracy of class 3 : 88.241341991342\n",
            "Result for hidden neurons : 100 :\n",
            "Fold 1 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        13   0   3\n",
            "2.0         0  14   0\n",
            "3.0         0   0  11\n",
            "Accuracy of class1 : 81.25\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 1 Accuracy : 92.6829268292683\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        16   0   1\n",
            "2.0         0  12   0\n",
            "3.0         1   0  11\n",
            "Accuracy of class1 : 94.11764705882352\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 91.66666666666666\n",
            "Fold 2 Accuracy : 95.1219512195122\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        14   0   0\n",
            "2.0         0  13   0\n",
            "3.0         1   0  13\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 92.85714285714286\n",
            "Fold 3 Accuracy : 97.5609756097561\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        8   1   0\n",
            "2.0        0  16   0\n",
            "3.0        2   0  14\n",
            "Accuracy of class1 : 88.88888888888889\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 87.5\n",
            "Fold 4 Accuracy : 92.6829268292683\n",
            "Fold 5 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        10   1   2\n",
            "2.0         0  14   1\n",
            "3.0         0   0  17\n",
            "Accuracy of class1 : 76.92307692307693\n",
            "Accuracy of class2 : 93.33333333333333\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 5 Accuracy : 91.11111111111111\n",
            "Average Accuracy : 93.8319783197832\n",
            "Average Accuracy of class 1 : 88.23592257415788\n",
            "Average Accuracy of class 2 : 98.66666666666667\n",
            "Average Accuracy of class 3 : 94.4047619047619\n",
            "Result for hidden neurons : 110 :\n",
            "Fold 1 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        16   0   0\n",
            "2.0         0  14   0\n",
            "3.0         1   0  10\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 90.9090909090909\n",
            "Fold 1 Accuracy : 97.5609756097561\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        16   0   1\n",
            "2.0         0  12   0\n",
            "3.0         1   0  11\n",
            "Accuracy of class1 : 94.11764705882352\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 91.66666666666666\n",
            "Fold 2 Accuracy : 95.1219512195122\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        14   0   0\n",
            "2.0         0  13   0\n",
            "3.0         2   0  12\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 85.71428571428571\n",
            "Fold 3 Accuracy : 95.1219512195122\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        8   1   0\n",
            "2.0        2  14   0\n",
            "3.0        1   0  15\n",
            "Accuracy of class1 : 88.88888888888889\n",
            "Accuracy of class2 : 87.5\n",
            "Accuracy of class3 : 93.75\n",
            "Fold 4 Accuracy : 90.2439024390244\n",
            "Fold 5 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        10   0   3\n",
            "2.0         0  15   0\n",
            "3.0         1   0  16\n",
            "Accuracy of class1 : 76.92307692307693\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 94.11764705882352\n",
            "Fold 5 Accuracy : 91.11111111111111\n",
            "Average Accuracy : 93.8319783197832\n",
            "Average Accuracy of class 1 : 91.98592257415788\n",
            "Average Accuracy of class 2 : 97.5\n",
            "Average Accuracy of class 3 : 91.23153806977336\n",
            "Result for hidden neurons : 120 :\n",
            "Fold 1 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        14   1   1\n",
            "2.0         0  14   0\n",
            "3.0         0   0  11\n",
            "Accuracy of class1 : 87.5\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 1 Accuracy : 95.1219512195122\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        14   1   2\n",
            "2.0         0  12   0\n",
            "3.0         0   0  12\n",
            "Accuracy of class1 : 82.35294117647058\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 2 Accuracy : 92.6829268292683\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        14   0   0\n",
            "2.0         3  10   0\n",
            "3.0         1   0  13\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 76.92307692307693\n",
            "Accuracy of class3 : 92.85714285714286\n",
            "Fold 3 Accuracy : 90.2439024390244\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        8   1   0\n",
            "2.0        1  15   0\n",
            "3.0        4   0  12\n",
            "Accuracy of class1 : 88.88888888888889\n",
            "Accuracy of class2 : 93.75\n",
            "Accuracy of class3 : 75.0\n",
            "Fold 4 Accuracy : 85.36585365853658\n",
            "Fold 5 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        9   2   2\n",
            "2.0        2  13   0\n",
            "3.0        0   1  16\n",
            "Accuracy of class1 : 69.23076923076923\n",
            "Accuracy of class2 : 86.66666666666667\n",
            "Accuracy of class3 : 94.11764705882352\n",
            "Fold 5 Accuracy : 84.44444444444444\n",
            "Average Accuracy : 89.57181571815717\n",
            "Average Accuracy of class 1 : 85.59451985922573\n",
            "Average Accuracy of class 2 : 91.4679487179487\n",
            "Average Accuracy of class 3 : 92.39495798319328\n",
            "Result for hidden neurons : 130 :\n",
            "Fold 1 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        14   0   2\n",
            "2.0         0  14   0\n",
            "3.0         0   0  11\n",
            "Accuracy of class1 : 87.5\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 1 Accuracy : 95.1219512195122\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        17   0   0\n",
            "2.0         0  12   0\n",
            "3.0         1   0  11\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 91.66666666666666\n",
            "Fold 2 Accuracy : 97.5609756097561\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        13   1   0\n",
            "2.0         2  11   0\n",
            "3.0         1   1  12\n",
            "Accuracy of class1 : 92.85714285714286\n",
            "Accuracy of class2 : 84.61538461538461\n",
            "Accuracy of class3 : 85.71428571428571\n",
            "Fold 3 Accuracy : 87.8048780487805\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        6   2   1\n",
            "2.0        2  14   0\n",
            "3.0        4   0  12\n",
            "Accuracy of class1 : 66.66666666666666\n",
            "Accuracy of class2 : 87.5\n",
            "Accuracy of class3 : 75.0\n",
            "Fold 4 Accuracy : 78.04878048780488\n",
            "Fold 5 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        9   1   3\n",
            "2.0        2  13   0\n",
            "3.0        1   0  16\n",
            "Accuracy of class1 : 69.23076923076923\n",
            "Accuracy of class2 : 86.66666666666667\n",
            "Accuracy of class3 : 94.11764705882352\n",
            "Fold 5 Accuracy : 84.44444444444444\n",
            "Average Accuracy : 88.5962059620596\n",
            "Average Accuracy of class 1 : 83.25091575091575\n",
            "Average Accuracy of class 2 : 91.75641025641026\n",
            "Average Accuracy of class 3 : 89.29971988795518\n",
            "Result for hidden neurons : 140 :\n",
            "Fold 1 :\n",
            "Predicted   1  2   3\n",
            "Actual              \n",
            "1.0        11  3   2\n",
            "2.0         4  9   1\n",
            "3.0         1  0  10\n",
            "Accuracy of class1 : 68.75\n",
            "Accuracy of class2 : 64.28571428571429\n",
            "Accuracy of class3 : 90.9090909090909\n",
            "Fold 1 Accuracy : 73.17073170731707\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        16   1   0\n",
            "2.0         0  10   2\n",
            "3.0         2   0  10\n",
            "Accuracy of class1 : 94.11764705882352\n",
            "Accuracy of class2 : 83.33333333333334\n",
            "Accuracy of class3 : 83.33333333333334\n",
            "Fold 2 Accuracy : 87.8048780487805\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        13   1   0\n",
            "2.0         1  11   1\n",
            "3.0         0   1  13\n",
            "Accuracy of class1 : 92.85714285714286\n",
            "Accuracy of class2 : 84.61538461538461\n",
            "Accuracy of class3 : 92.85714285714286\n",
            "Fold 3 Accuracy : 90.2439024390244\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        7   2   0\n",
            "2.0        2  14   0\n",
            "3.0        4   0  12\n",
            "Accuracy of class1 : 77.77777777777779\n",
            "Accuracy of class2 : 87.5\n",
            "Accuracy of class3 : 75.0\n",
            "Fold 4 Accuracy : 80.48780487804879\n",
            "Fold 5 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        9   1   3\n",
            "2.0        2  13   0\n",
            "3.0        0   0  17\n",
            "Accuracy of class1 : 69.23076923076923\n",
            "Accuracy of class2 : 86.66666666666667\n",
            "Accuracy of class3 : 100.0\n",
            "Fold 5 Accuracy : 86.66666666666667\n",
            "Average Accuracy : 83.67479674796748\n",
            "Average Accuracy of class 1 : 80.54666738490268\n",
            "Average Accuracy of class 2 : 81.28021978021978\n",
            "Average Accuracy of class 3 : 88.41991341991343\n",
            "Result for hidden neurons : 150 :\n",
            "Fold 1 :\n",
            "Predicted   1  2  3\n",
            "Actual             \n",
            "1.0        11  2  3\n",
            "2.0         5  9  0\n",
            "3.0         2  1  8\n",
            "Accuracy of class1 : 68.75\n",
            "Accuracy of class2 : 64.28571428571429\n",
            "Accuracy of class3 : 72.72727272727273\n",
            "Fold 1 Accuracy : 68.29268292682927\n",
            "Fold 2 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        15   0   2\n",
            "2.0         0  12   0\n",
            "3.0         2   0  10\n",
            "Accuracy of class1 : 88.23529411764706\n",
            "Accuracy of class2 : 100.0\n",
            "Accuracy of class3 : 83.33333333333334\n",
            "Fold 2 Accuracy : 90.2439024390244\n",
            "Fold 3 :\n",
            "Predicted   1   2   3\n",
            "Actual               \n",
            "1.0        12   1   1\n",
            "2.0         1  10   2\n",
            "3.0         1   1  12\n",
            "Accuracy of class1 : 85.71428571428571\n",
            "Accuracy of class2 : 76.92307692307693\n",
            "Accuracy of class3 : 85.71428571428571\n",
            "Fold 3 Accuracy : 82.92682926829268\n",
            "Fold 4 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        7   1   1\n",
            "2.0        3  13   0\n",
            "3.0        5   0  11\n",
            "Accuracy of class1 : 77.77777777777779\n",
            "Accuracy of class2 : 81.25\n",
            "Accuracy of class3 : 68.75\n",
            "Fold 4 Accuracy : 75.60975609756098\n",
            "Fold 5 :\n",
            "Predicted  1   2   3\n",
            "Actual              \n",
            "1.0        9   0   4\n",
            "2.0        3  10   2\n",
            "3.0        5   0  12\n",
            "Accuracy of class1 : 69.23076923076923\n",
            "Accuracy of class2 : 66.66666666666666\n",
            "Accuracy of class3 : 70.58823529411765\n",
            "Fold 5 Accuracy : 68.88888888888889\n",
            "Average Accuracy : 77.19241192411926\n",
            "Average Accuracy of class 1 : 77.94162536809596\n",
            "Average Accuracy of class 2 : 77.82509157509156\n",
            "Average Accuracy of class 3 : 76.2226254138019\n",
            "[94.27642276 95.29539295 94.76422764 96.22764228 95.65311653 94.27642276\n",
            " 95.29539295 88.99728997 93.83197832 93.83197832 89.57181572 88.59620596\n",
            " 83.67479675 77.19241192] 3\n",
            "Best Result for 50 Hidden Neurons , Accuracy - 96.22764227642277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkuLWeOjvMu2"
      },
      "source": [
        "\n",
        "Only the best result has been presented here due to the long output\n",
        "```\n",
        "# This is formatted as code\n",
        "Best Result for 50 Hidden Neurons , Accuracy - 95.20867208672087\n",
        "Result for hidden neurons : 50 :\n",
        "Fold 1 :\n",
        "Predicted   1   2   3\n",
        "Actual               \n",
        "1.0        15   0   1\n",
        "2.0         0  13   0\n",
        "3.0         2   0  10\n",
        "Accuracy of class1 : 93.75\n",
        "Accuracy of class2 : 100.0\n",
        "Accuracy of class3 : 83.33333333333334\n",
        "Fold 1 Accuracy : 92.6829268292683\n",
        "Fold 2 :\n",
        "Predicted   1  2   3\n",
        "Actual              \n",
        "1.0        14  0   2\n",
        "2.0         0  9   0\n",
        "3.0         0  0  16\n",
        "Accuracy of class1 : 87.5\n",
        "Accuracy of class2 : 100.0\n",
        "Accuracy of class3 : 100.0\n",
        "Fold 2 Accuracy : 95.1219512195122\n",
        "Fold 3 :\n",
        "Predicted   1   2   3\n",
        "Actual               \n",
        "1.0        12   0   0\n",
        "2.0         1  12   0\n",
        "3.0         1   0  15\n",
        "Accuracy of class1 : 100.0\n",
        "Accuracy of class2 : 92.3076923076923\n",
        "Accuracy of class3 : 93.75\n",
        "Fold 3 Accuracy : 95.1219512195122\n",
        "Fold 4 :\n",
        "Predicted   1   2   3\n",
        "Actual               \n",
        "1.0        14   0   0\n",
        "2.0         0  15   0\n",
        "3.0         1   0  11\n",
        "Accuracy of class1 : 100.0\n",
        "Accuracy of class2 : 100.0\n",
        "Accuracy of class3 : 91.66666666666666\n",
        "Fold 4 Accuracy : 97.5609756097561\n",
        "Fold 5 :\n",
        "Predicted  1   2   3\n",
        "Actual              \n",
        "1.0        9   1   1\n",
        "2.0        0  20   0\n",
        "3.0        0   0  14\n",
        "Accuracy of class1 : 81.81818181818183\n",
        "Accuracy of class2 : 100.0\n",
        "Accuracy of class3 : 100.0\n",
        "Fold 5 Accuracy : 95.55555555555556\n",
        "Average Accuracy : 95.20867208672087\n",
        "Average Accuracy of class 1 : 92.61363636363637\n",
        "Average Accuracy of class 2 : 98.46153846153847\n",
        "Average Accuracy of class 3 : 93.75\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 7\n",
        "Implement a deep neural network, which contains two hidden layers (the hidden layers are obtained from the ELM-autoencoders). The last layer will be the ELM layer which means the second hidden layer feature vector is used as input to the ELM classifier. The network can be called as deep layer stacked autoencoder based extreme learning machine. You can use holdout approach (70, 10, 20%) for evaluating the performance of the classifier. The dataset (data5.xlsx) contains 7 features and the last column is the output (class labels). Evaluate individual accuracy and overall accuracy. (Packages such as Scikitlearn, keras, tensorflow, pytorch etc. are not allowed)"
      ],
      "metadata": {
        "id": "g_4hvDnibpG6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ92lz7XWN-4"
      },
      "source": [
        "sheet1 = pd.read_excel('data5.xlsx')\n",
        "data = sheet1.values\n",
        "np.random.shuffle(data)\n",
        "X = data[0: , : 7]\n",
        "X = (X - np.min(X,axis=0))/(np.max(X,axis=0)- np.min(X,axis=0))\n",
        "Y = data[0: , 7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcHMoRBA0duo"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X,Y, train_size=0.7)\n",
        "x_valid, x_test, y_valid, y_test = train_test_split(x_test,y_test, test_size=0.33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofW_yfKSWN-4"
      },
      "source": [
        "def sigmoid(z):\n",
        "    z = z.astype(float)\n",
        "    z_output =1/(1 + np.exp(-z))\n",
        "    return z_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5dA1d3PWN-4"
      },
      "source": [
        "def sigmoid_derivative(z):\n",
        "  derivative = z*(1-z)\n",
        "  return derivative"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqxBIUGJWN-5"
      },
      "source": [
        "def Predictions(Output):\n",
        "  y_pred = []\n",
        "  Output = list(Output)\n",
        "  for i in range(len(Output)):\n",
        "    Output[i] = list(Output[i])\n",
        "    max_val = max(Output[i])\n",
        "    max_index = Output[i].index(max_val)\n",
        "    y_pred.append(max_index+1)\n",
        "  y_pred = np.array(y_pred)\n",
        "  return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2okFaKCYD2o"
      },
      "source": [
        "def one_vs_all(y):\n",
        "  y_model1 = []\n",
        "  y_model2 = []\n",
        "  y_model3 = []\n",
        "  for ele in y:\n",
        "    if (ele == 1):\n",
        "      y_model1.append(1)\n",
        "      y_model2.append(0)\n",
        "      y_model3.append(0)\n",
        "    if (ele == 2):\n",
        "      y_model1.append(0)\n",
        "      y_model2.append(1)\n",
        "      y_model3.append(0)\n",
        "    if (ele == 3):\n",
        "      y_model1.append(0)\n",
        "      y_model2.append(0)\n",
        "      y_model3.append(1)\n",
        "  return y_model1,y_model2,y_model3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hJRY_TKWN-5"
      },
      "source": [
        "def model(X,hidden_nodes,output_dim=3):\n",
        "\n",
        "    input_dim = X.shape[1]\n",
        "    W1 = np.random.randn(input_dim, hidden_nodes) / np.sqrt(input_dim)\n",
        "    b1 = np.zeros((1, hidden_nodes))\n",
        "    W2 = np.random.randn(hidden_nodes, hidden_nodes) / np.sqrt(hidden_nodes)\n",
        "    b2 = np.zeros((1, hidden_nodes))\n",
        "    W3 = np.random.randn(hidden_nodes, output_dim) / np.sqrt(hidden_nodes)\n",
        "    b3 = np.zeros((1, output_dim))\n",
        "\n",
        "    return W1,b1,W2,b2,W3,b3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3xvXfdfWN-5"
      },
      "source": [
        "def sae_ffn(X,W1,b1,W2,b2,W3,b3):\n",
        "  z1 = np.dot(X,W1) + b1\n",
        "  a1 = sigmoid(z1)\n",
        "  z2 = np.dot(a1,W2) + b2\n",
        "  a2 = sigmoid(z2)\n",
        "  z3 = np.dot(a2,W3) + b3\n",
        "  return z1,z2,z3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0THXmw0MWN-5"
      },
      "source": [
        "def sae_bp(X,Y,W1,W2,W3,a1,a2,a3,p):\n",
        "  rho = 1\n",
        "  rho_o =0.5\n",
        "  beta = 0.01\n",
        "  m = X.shape[1]\n",
        "  KL = beta * (-(rho / rho_o) + ((1 - rho) / (1 - rho_o)))\n",
        "  delta3 = np.zeros((p,3))\n",
        "  dW3 = np.zeros((p,3))\n",
        "  delta_o3 = np.zeros((p,3))\n",
        "  dW2 = np.zeros((p,p))\n",
        "  delta_o2 = np.zeros((p,p))\n",
        "  dW1 = np.zeros((m,p))\n",
        "  delta_o1 = np.zeros((m,p))\n",
        "  db3 = np.zeros(3)\n",
        "  db2 = np.zeros(p)\n",
        "  db1 = np.zeros(m)\n",
        "  for k in range(3):\n",
        "    delta3[k] = Y[k] - Predictions(a3[k])\n",
        "    delta_o3[k] = np.multiply(delta3[k],Predictions(sigmoid_derivative(a3[k])))\n",
        "    dW3[k] = np.dot(np.transpose(delta_o3[k]),a2)\n",
        "    db3[k] = delta_o3[k]\n",
        "  for i in range(p):\n",
        "    dW2[i],db2[i],delta_o2[i] = delta_derivative(W3[i],delta_o3,KL,a1[i],a2[i])\n",
        "  for j in range(m):\n",
        "    dW1[j],db1[j],delta_o1[j] = delta_derivative(W2[j],delta_o2,KL,X[j],a1[j])\n",
        "\n",
        "  return dW1, dW2, dW3, db1, db2, db3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfjeQ6nGWN-5"
      },
      "source": [
        "def delta_derivative(w,delta_o,k,a_prev,a):\n",
        "  delta_n = np.multiply(sum(np.dot(np.transpose(w), delta_o)) + k ,np.multiply(a, 1 - a))\n",
        "  dW =np.dot(delta_n,np.transpose(a_prev))\n",
        "  db = np.sum(delta_n,axis=0,keepdims=True)\n",
        "  return dW,db,delta_n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKhY3mKaWN-6"
      },
      "source": [
        "def Stacked_autoencoder(X,Y,alpha,lamda,p):\n",
        "  W1,b1,W2,b2,W3,b3 = model(X,p,3)\n",
        "  for i in range(500):\n",
        "    a1,a2,a3 = sae_ffn(X,W1,b1,W2,b2,W3,b3)\n",
        "    dW1, dW2, dW3, db1, db2, db3 = sae_bp(X,Y,W1,W2,W3,a1,a2,a3,p)\n",
        "    W1 -= alpha * (dW1 + lamda*W1)\n",
        "    b1 -= alpha * db1\n",
        "    W2 -= alpha * (dW2 + lamda*W2)\n",
        "    b2 -= alpha * db2\n",
        "    W3 -= alpha * (dW3 + lamda*W3)\n",
        "    b3 -= alpha * db3\n",
        "    return W1,b1,W2,b2,W3,b3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9_jp8KpWaJf"
      },
      "source": [
        "def elm_input(x,y,hidden_neurons_opt):\n",
        "  w1,b1,w2,b2,w3,b3 = Stacked_autoencoder(x,y,0.01,0.01,hidden_neurons_opt)\n",
        "  z1,z2,out = sae_ffn(x,w1,b1,w2,b2,w3,b3)\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxFTMswnW-eQ"
      },
      "source": [
        "def elm_fn(x,y,p):\n",
        "  elm_train_input = elm_input(x_train,y_train,p)\n",
        "  elm_test_input = elm_input(x,y,p)\n",
        "  randommat = np.random.randn(elm_train_input.shape[ 1 ]+ 1 ,p)\n",
        "  H = np.append(np.ones((elm_train_input.shape[ 0 ], 1 )),elm_train_input, axis= 1 )\n",
        "  H = np.dot(H,randommat)\n",
        "  H = np.tanh(H)\n",
        "  H = np.matrix(H)\n",
        "  y_tr1,y_tr2,y_tr3 = one_vs_all(y_train)\n",
        "  w1= np.dot(H.I,np.transpose(y_tr1))\n",
        "  w2= np.dot(H.I,np.transpose(y_tr2))\n",
        "  w3= np.dot(H.I,np.transpose(y_tr3))\n",
        "  p_outputs = []\n",
        "  H_ts = np.append(np.ones((elm_test_input.shape[ 0 ], 1 )),elm_test_input, axis= 1 )\n",
        "  H_ts = np.dot(H_ts,randommat)\n",
        "  H_ts = np.tanh(H_ts)\n",
        "  H_ts = np.matrix(H_ts)\n",
        "  for b in range(len(H_ts)):\n",
        "    pred_op = []\n",
        "    Z1 = np.dot(H_ts[b],w1.T)\n",
        "    pred_op.append(sigmoid(Z1))\n",
        "    Z2 = np.dot(H_ts[b],w2.T)\n",
        "    pred_op.append(sigmoid(Z2))\n",
        "    Z3 = np.dot(H_ts[b],w3.T)\n",
        "    pred_op.append(sigmoid(Z3))\n",
        "    pred_op = np.array(pred_op)\n",
        "    p_outputs.append(np.argmax(pred_op)+1)\n",
        "    pred_op = pred_op.tolist()\n",
        "  y_actual = pd.Series(y, name= 'Actual' )\n",
        "  y_pred = pd.Series(p_outputs, name= 'Predicted' )\n",
        "  confmat = pd.crosstab(y_actual,y_pred)\n",
        "  #print (confmat)\n",
        "  confmat = np.asarray(confmat)\n",
        "  class_acc = np.zeros(3)\n",
        "  for i in range(3):\n",
        "    num = confmat[i][i]\n",
        "    s =0\n",
        "    for j in range(3):\n",
        "      s += confmat[i][j]\n",
        "    class_acc[i]= num/s\n",
        "  acc = np.trace(confmat)/np.sum(confmat)\n",
        "  return class_acc,acc,confmat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymUyZh6EvyQS"
      },
      "source": [
        "#Grid_search\n",
        "acc_list = []\n",
        "hidden = []\n",
        "for i in range(10,51,5):\n",
        "  hidden.append(i)\n",
        "  cl_acc,accu,cm1 = elm_fn(x_valid,y_valid,i)\n",
        "  acc_list.append(accu)\n",
        "opt_val = max(acc_list)\n",
        "opt_ind = acc_list.index(opt_val)\n",
        "hidden_neurons_opt = hidden[opt_ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjO2i3LWx3PZ",
        "outputId": "72ca0cbb-0ce8-4b1d-c874-72c613b5639e"
      },
      "source": [
        "class_accuracy,accuracy,conf_mat = elm_fn(x_test,y_test,hidden_neurons_opt)\n",
        "print(conf_mat)\n",
        "for c in range(3):\n",
        "  print( 'Accuracy of class'+ str(c+1)+' : ' + str(class_accuracy[c]*100))\n",
        "print( 'Overall  Accuracy : ' + str(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted   1   2  3\n",
            "Actual              \n",
            "1.0        10   1  2\n",
            "2.0         2  10  8\n",
            "3.0         0   1  8\n",
            "Accuracy of class1 : 76.92307692307693\n",
            "Accuracy of class2 : 50.0\n",
            "Accuracy of class3 : 88.88888888888889\n",
            "Overall  Accuracy : 66.66666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpMSSNREwcI1"
      },
      "source": [
        "# Question 8\n",
        "Implement support vector machine (SVM) classifier for the multi-class classification task. You can use one\n",
        "vs one and one vs all multiclass coding methods to create binary SVM models. Implement the SMO\n",
        "algorithm for the evaluation of the training parameters of SVM such as Lagrange multipliers. You can use\n",
        "holdout approach (70%, 10%, 20%) for evaluating the performance of the classifier. The dataset\n",
        "(data5.xlsx) contains 7 features and the last column is the output (class labels). Evaluate individual\n",
        "accuracy and overall accuracy. You can use RBF and polynomial kernels. Evaluate the classification\n",
        "performance of multiclass SVM for each kernel function. (Packages such as Scikitlearn, keras, tensorflow,\n",
        "pytorch etc. are not allowed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLAwLWpM3Vm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a54d1df-bd0b-47bc-e317-8e931ed9c81b"
      },
      "source": [
        "%reset\n",
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW7H9nLF3aM8"
      },
      "source": [
        "sheet1 = pd.read_excel('data5.xlsx')\n",
        "data = sheet1.values\n",
        "np.random.shuffle(data)\n",
        "x = data[0: , :-1]\n",
        "x = (x - np.min(x,axis=0))/(np.max(x,axis=0)- np.min(x,axis=0))\n",
        "y = data[0: , -1]\n",
        "x_train,X_test,y_train,y_test = train_test_split(x, y, test_size= 0.2 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOmtxW2n3aM-"
      },
      "source": [
        "def one_vs_all(y):\n",
        "  y_model1 = []\n",
        "  y_model2 = []\n",
        "  y_model3 = []\n",
        "  for ele in y:\n",
        "    if (ele == 1):\n",
        "      y_model1.append(1)\n",
        "      y_model2.append(-1)\n",
        "      y_model3.append(-1)\n",
        "    if (ele == 2):\n",
        "      y_model1.append(-1)\n",
        "      y_model2.append(1)\n",
        "      y_model3.append(-1)\n",
        "    if (ele == 3):\n",
        "      y_model1.append(-1)\n",
        "      y_model2.append(-1)\n",
        "      y_model3.append(1)\n",
        "  return y_model1,y_model2,y_model3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_onLfbhIDvU"
      },
      "source": [
        "def train_lin_sum (x_tr,y_tr,C,bound,maxiters):\n",
        "  m = x_tr.shape[0]\n",
        "  n = x_tr.shape[1]\n",
        "  b = 0\n",
        "  #mean = np.zeros(m)\n",
        "  #cov = np.identity(m)\n",
        "  #mu = np.random.multivariate_normal(mean, cov)\n",
        "  mu = np.ones((m,1))\n",
        "  E = np.zeros((m,1))\n",
        "  iter = 0\n",
        "  eta =0\n",
        "  L =0\n",
        "  H = 0\n",
        "  kernel = lambda xi, yi: math.pow((np.dot(xi.T, yi) + 1), 2)\n",
        "  while iter<maxiters:\n",
        "    count_mu = 0\n",
        "    for i in range(m):\n",
        "      E[i] = f_x(x_tr, y_tr, mu, b, x_tr[i, :], 2) - y_tr[i]\n",
        "      if (y_tr[i]*E[i]<-bound and mu[i]<C) or (y_tr[i]*E[i]>bound and mu[i]>0):\n",
        "        j = math.floor(m*np.random.rand())\n",
        "        while j == i:\n",
        "          j = math.floor(m*np.random.rand())\n",
        "        E[j] = f_x(x_tr, y_tr, mu, b, x_tr[j, :], 2) - y_tr[j]\n",
        "        mu_i_old = mu[i]\n",
        "        mu_j_old = mu[j]\n",
        "        if y_tr[i] == y_tr[j]:\n",
        "          L = max(0, mu[i]+mu[j]-C)\n",
        "          H = min(C,mu[i]+mu[j])\n",
        "        else:\n",
        "          L = max(0,mu[j]-mu[i])\n",
        "          H = min(C,C+mu[j]-mu[i])\n",
        "        if (L == H):\n",
        "          continue\n",
        "        eta = 2*kernel(x_tr[i, :], x_tr[j, :]) - kernel(x_tr[i, :], x_tr[i, :]) - kernel(x_tr[j, :], x_tr[j, :])\n",
        "        if eta>=0:\n",
        "          continue\n",
        "        mu[j] = mu[j] - (y_tr[j]*(E[i]-E[j]))/eta\n",
        "        mu[j] = min(H,mu[j])\n",
        "        mu[j] = max(L,mu[j])\n",
        "        if abs(mu[j]-mu_j_old)<bound:\n",
        "          mu[j] = mu_j_old\n",
        "          continue\n",
        "        mu[i] = mu[i]+y_tr[i]*y_tr[j]*(mu_j_old-mu[j])\n",
        "        b1 = b - E[i]- (y_tr[i]*(mu[i]-mu_i_old)*kernel(x_tr[i, :], x_tr[i, :]))  - (y_tr[j]*(mu[j]-mu_j_old)*kernel(x_tr[i, :], x_tr[j, :]))\n",
        "        b2 = b - E[j]- (y_tr[i]*(mu[i]-mu_i_old)*kernel(x_tr[i, :], x_tr[j, :])) - (y_tr[j]*(mu[j]-mu_j_old)*kernel(x_tr[j, :], x_tr[j, :]))\n",
        "        if (0<mu[i]) and (mu[i]<C):\n",
        "          b = b1\n",
        "        elif (0<mu[j]) and (mu[j]<C):\n",
        "          b = b2\n",
        "        else:\n",
        "          b = (b1+b2)/2\n",
        "        count_mu = count_mu +1\n",
        "    if (count_mu == 0):\n",
        "      iter = iter+1\n",
        "    else:\n",
        "      iter = 0\n",
        "  il1 = mu>0\n",
        "  Xsvm = []\n",
        "  Ysvm = []\n",
        "  mus = []\n",
        "  for v in range(len(il1)):\n",
        "    if il1[v]:\n",
        "      Xsvm.append(x_tr[v,:])\n",
        "      Ysvm.append(y_tr[v])\n",
        "      mus.append(mu[v])\n",
        "  Xsvm = np.array(Xsvm)\n",
        "  Ysvm = np.array(Ysvm)\n",
        "  mus = np.array(mus)\n",
        "  #s = mus.shape[1]\n",
        "  w = np.zeros(7)\n",
        "  num_sv = Xsvm.shape[1]\n",
        "  for l in range(7):\n",
        "    w += mus[l]*Ysvm[l]*((1 + Xsvm[l,:])**2)\n",
        "  return w,b,Xsvm,Ysvm,mus,num_sv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOwTPAzMatf1"
      },
      "source": [
        "def f_x(X, y, a, b, x, degree):\n",
        "    predicted_value = 0.0\n",
        "    # using polynomial kernel\n",
        "    for k in range(X.shape[0]):\n",
        "        predicted_value += (a[k]*y[k]*((X[k, :].T@x + 1)**degree))\n",
        "    return predicted_value + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPzdUGzujDYG"
      },
      "source": [
        "def sigmoid(z):\n",
        "  return 1.0 / ( 1.0 + np.exp(-z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-osWhzuM_izF"
      },
      "source": [
        "def prediction(xs,ys,x_ts,mean,bias,n_svm):\n",
        "  yp = 0\n",
        "  for s in range(n_svm):\n",
        "    yp += (mean[s]*ys[s]*np.dot(x_ts,xs[s]))\n",
        "  return np.sign(yp+bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqs7dr_FwPkU"
      },
      "source": [
        "C = 100\n",
        "# kernelFunc = linear\n",
        "iters =100\n",
        "p_outputs = []\n",
        "y_tr1,y_tr2,y_tr3 = one_vs_all(y_train)\n",
        "y_ts1,y_ts2,y_ts3 = one_vs_all(y_test)\n",
        "w1,b1,x1,y1,m1,n1= train_lin_sum(x_train,y_tr1,C,0.001,iters)\n",
        "w2,b2,x2,y2,m2,n2= train_lin_sum(x_train,y_tr2,C,0.001,iters)\n",
        "w3,b3,x3,y3,m3,n3= train_lin_sum(x_train,y_tr3,C,0.001,iters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGX97aJSIalF"
      },
      "source": [
        "yp1 = []\n",
        "yp2 = []\n",
        "yp3 = []\n",
        "lis = [-1,1]\n",
        "for b in range(len(X_test)):\n",
        "  if f_x(x1, y1, m1, b1, X_test[b, :], 4) >= 0:\n",
        "    yp1.append(1.0)\n",
        "  else:\n",
        "    yp1.append(-1.0)\n",
        "  if f_x(x2, y2, m2, b2, X_test[b, :], 4) >= 0:\n",
        "    yp2.append(1.0)\n",
        "  else:\n",
        "    yp2.append(-1.0)\n",
        "  if f_x(x3, y3, m3, b3, X_test[b, :], 4) >= 0:\n",
        "    yp3.append(1.0)\n",
        "  else:\n",
        "    yp3.append(-1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRiegs1zIalH",
        "outputId": "61852c54-0bf7-49d2-e11c-a13814add3d3"
      },
      "source": [
        "y_actual1 = pd.Series(y_ts1, name= 'Actual' )\n",
        "y_pred1 = pd.Series(yp1, name= 'Predicted' )\n",
        "confmat1 = pd.crosstab(y_actual1,y_pred1)\n",
        "\n",
        "y_actual2 = pd.Series(y_ts2, name= 'Actual' )\n",
        "y_pred2 = pd.Series(yp2, name= 'Predicted' )\n",
        "confmat2 = pd.crosstab(y_actual2,y_pred2)\n",
        "\n",
        "y_actual3 = pd.Series(y_ts3, name= 'Actual' )\n",
        "y_pred3 = pd.Series(yp3, name= 'Predicted' )\n",
        "confmat3 = pd.crosstab(y_actual3,y_pred3)\n",
        "print(y_actual3.shape)\n",
        "print(y_pred3.shape)\n",
        "print(confmat3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42,)\n",
            "(42,)\n",
            "(2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWfoA3j2EIXG"
      },
      "source": [
        "def accuracy_val(confmat):\n",
        "  class_acc = np.zeros(3)\n",
        "  confmat = np.asarray(confmat)\n",
        "  for i in range(len(confmat)):\n",
        "    num = confmat[i][ min(i,len(confmat[i])-1) ]\n",
        "    confmat[0][0]+=num\n",
        "    s =0\n",
        "    for j in range(len(confmat[i])):\n",
        "      s += confmat[i][j]\n",
        "    class_acc[i]= num/s\n",
        "  acc = np.trace(confmat)/np.sum(confmat)\n",
        "  return acc*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxXqKqwVF0gt",
        "outputId": "8d6880a5-4068-474d-bcae-a40d5eabd7fd"
      },
      "source": [
        "acc1 = accuracy_val(confmat1)\n",
        "print( 'Class 1 Accuracy : ' + str(acc1))\n",
        "acc2 = accuracy_val(confmat2)\n",
        "print( 'Class 2 Accuracy : ' + str(acc2))\n",
        "acc3 = accuracy_val(confmat3)\n",
        "print( 'Class 3 Accuracy : ' + str(acc3))\n",
        "ovr_acc = (acc1+acc2+acc3)/3\n",
        "print(\"Overall Accuracy :\", ovr_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1 Accuracy : 80.95238095238095\n",
            "Class 2 Accuracy : 92.85714285714286\n",
            "Class 3 Accuracy : 76.19047619047619\n",
            "Overall Accuracy : 83.33333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQNFDXnOwlv-"
      },
      "source": [
        "# Question 9\n",
        "Implement a multi-channel 1D deep CNN architecture (as shown in Fig. 1) for the seven-class classification\n",
        "task. The input and the class labels are given in. mat file format. There is a total of 17160 number of\n",
        "instances present in both input and class-label data files. The input data for each instance is a\n",
        "multichannel time series (12-channel) with size as (12 800). The class label for each multichannel time\n",
        "series instance is given in the class_label.mat file. You can select the training and test instances using\n",
        "\n",
        "hold-out cross-validation (70% training, 10% validation, and 20% testing). The architecture of the multi-\n",
        "channel deep CNN is given as follows. The number of filters, length of each filter, and number of neurons\n",
        "\n",
        "in the fully connected layers are shown in the following figure. Evaluate individual accuracy and overall\n",
        "accuracy. (Packages such as Scikitlearn, keras, tensorflow, pytorch etc. are allowed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTujAPpV4UBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dccc526-73d3-4211-dfef-5d15b9d31a7a"
      },
      "source": [
        "!pip install mat4py\n",
        "from mat4py import loadmat\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io as sio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Input, Dense, Activation, Flatten, Conv1D, Dropout,MaxPooling1D,MaxPool1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from mat4py import loadmat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mat4py\n",
            "  Downloading mat4py-0.5.0-py2.py3-none-any.whl (13 kB)\n",
            "Installing collected packages: mat4py\n",
            "Successfully installed mat4py-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ftr = sio.loadmat(\"./input.mat\")\n",
        "ftr_vec = pd.DataFrame(ftr[\"x\"])\n",
        "ftr_vec=(np.asarray(ftr_vec)).T\n",
        "\n",
        "class_label = sio.loadmat(\"./class_label.mat\")\n",
        "Y=np.asarray(class_label[\"y\"])\n",
        "\n",
        "X=[a[0] for a in ftr_vec]\n",
        "X=np.asarray(X)\n",
        "X=X.transpose(0,2,1)\n",
        "\n",
        "for i in range(len(X)):\n",
        "  X[i]=preprocessing.normalize(X[i])\n",
        "\n",
        "y=[]\n",
        "for i in range(len(Y)):\n",
        "  y.append(Y[i][0]-1)\n",
        "y=np.asarray(y)\n"
      ],
      "metadata": {
        "id": "BCeL1NTI8Yw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy8o8KYW51R4"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.2,train_size=0.8,random_state=0)\n",
        "X_train,X_valid,Y_train,Y_valid=train_test_split(X_train,Y_train,train_size=7/8,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOGFTrsh5358"
      },
      "source": [
        "def CNN_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(kernel_size=7,filters=20,input_shape = (800,12)))\n",
        "  model.add(MaxPool1D(pool_size=3, strides=3))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Conv1D(kernel_size=7,filters=60))\n",
        "  model.add(MaxPool1D(pool_size=3, strides=3))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(0.7))\n",
        "  model.add(Conv1D(kernel_size=7,filters=120))\n",
        "  model.add(Conv1D(kernel_size=7,filters=120))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(2000,activation = 'relu'))\n",
        "  model.add(Dense(700))\n",
        "  model.add(Dense(50))\n",
        "  model.add(Dense(7,activation = 'sigmoid'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeiVxsTK6MlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cbe3db0-a2a0-4192-8b32-5717ae5a1ded"
      },
      "source": [
        "model1 = CNN_model()\n",
        "model1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "execution_history=model1.fit(X_train, Y_train, epochs=7, batch_size=1000,validation_data=(X_valid,Y_valid))\n",
        "print(execution_history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "13/13 [==============================] - 63s 5s/step - loss: 2.3698 - accuracy: 0.3627 - val_loss: 1.1012 - val_accuracy: 0.5705\n",
            "Epoch 2/7\n",
            "13/13 [==============================] - 72s 6s/step - loss: 0.6619 - accuracy: 0.7641 - val_loss: 0.1111 - val_accuracy: 0.9831\n",
            "Epoch 3/7\n",
            "13/13 [==============================] - 63s 5s/step - loss: 0.1087 - accuracy: 0.9682 - val_loss: 0.0074 - val_accuracy: 0.9988\n",
            "Epoch 4/7\n",
            "13/13 [==============================] - 58s 4s/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 5.8521e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/7\n",
            "13/13 [==============================] - 58s 4s/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 1.6026e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/7\n",
            "13/13 [==============================] - 58s 4s/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 9.0218e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/7\n",
            "13/13 [==============================] - 60s 5s/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 5.2077e-05 - val_accuracy: 1.0000\n",
            "<keras.callbacks.History object at 0x7f9e887940d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zejyI0oL8Fuz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a44ca2c5-44c0-4a72-f644-487672c1aacc"
      },
      "source": [
        "model1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "execution_history=model1.fit(X_train, Y_train, epochs=5, batch_size=1000,validation_data=(X_valid,Y_valid))\n",
        "print(execution_history)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "13/13 [==============================] - 59s 4s/step - loss: 0.4055 - accuracy: 0.9252 - val_loss: 0.0128 - val_accuracy: 0.9994\n",
            "Epoch 2/5\n",
            "13/13 [==============================] - 57s 4s/step - loss: 0.0310 - accuracy: 0.9913 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "13/13 [==============================] - 61s 5s/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 1.8281e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "13/13 [==============================] - 57s 4s/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 4.8655e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "13/13 [==============================] - 58s 4s/step - loss: 8.1594e-04 - accuracy: 0.9998 - val_loss: 4.0924e-05 - val_accuracy: 1.0000\n",
            "<keras.callbacks.History object at 0x7f9e88749690>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pFKMA1FDgjX"
      },
      "source": [
        "y_pred = model1.predict(X_test)\n",
        "p_outputs = []\n",
        "for i in range(len(y_pred)):\n",
        "  p_outputs.append(np.argmax(y_pred[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3nGXBSPFJyj"
      },
      "source": [
        "def conf_mat(y_actual,y_predict):\n",
        "  y_actual = pd.Series(y_actual, name= 'Actual' )\n",
        "  y_p = pd.Series(y_predict, name= 'Predicted' )\n",
        "  confmat = pd.crosstab(y_actual,y_p)\n",
        "  return confmat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyfyrdtzFKTN"
      },
      "source": [
        "confusion_mat = conf_mat(Y_test,p_outputs)\n",
        "print(confusion_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdc-ROHhFLA_",
        "outputId": "12ef22d5-409b-4df0-b88f-30d95d102aae"
      },
      "source": [
        "confusion_mat = np.asarray(confusion_mat)\n",
        "class_acc = np.zeros(7)\n",
        "for i in range(7):\n",
        "  num = confusion_mat[i][i]\n",
        "  s =0\n",
        "  for j in range(7):\n",
        "    s += confusion_mat[i][j]\n",
        "  class_acc[i]= num/s\n",
        "\n",
        "ovr_acc = np.trace(confusion_mat)/np.sum(confusion_mat)\n",
        "for d in range(7):\n",
        "  print( 'Accuracy of class'+ str(d)+' : ' + str(class_acc[d]*100))\n",
        "print( 'Overall Accuracy : ' + str(ovr_acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of class0 : 100.0\n",
            "Accuracy of class1 : 100.0\n",
            "Accuracy of class2 : 99.5\n",
            "Accuracy of class3 : 100.0\n",
            "Accuracy of class4 : 95.1219512195122\n",
            "Accuracy of class5 : 100.0\n",
            "Accuracy of class6 : 96.67590027700831\n",
            "Overall Accuracy : 98.68881118881119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX-fF8CF6Vvw",
        "outputId": "2b86748d-aedc-4c60-f516-fae3a5a4d0f3"
      },
      "source": [
        "Loss , Accuracy = model1.evaluate(X_test,Y_test)\n",
        "print(\"Accuracy is\",Accuracy*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108/108 [==============================] - 6s 60ms/step - loss: 5.6289e-05 - accuracy: 1.0000\n",
            "Accuracy is 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyAgs3fmw2IP"
      },
      "source": [
        "# Question 10\n",
        "Implement the hybrid fuzzy deep neural network (HFDNN) for the three-class classification task. The input\n",
        "and output instances for the HFDNN are given in data5.xlsx file (first seven columns input and last column\n",
        "is the output). For a single instance, the input size is 7. There is a total of 210 instances given in the input\n",
        "and label datasets. You can select the training and test instances using hold-out cross-validation\n",
        "(70%training, 10% validation, and 20% testing). The HFDNN architecture shown in Fig. 2 has neural\n",
        "network hidden layers, fuzzy membership and rule layers, and a fusion layer. The descriptions of the\n",
        "\n",
        "HFDNN architecture are given in reference. Evaluate individual accuracy and overall accuracy. (Packages\n",
        "such as Scikitlearn, keras, tensorflow, pytorch etc. are not allowed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAoJ_FnwIsN8"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.compat.v1 as tf\n",
        "import math\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sibvx3PxMUek"
      },
      "source": [
        "def set(y):\n",
        "    for i in range(len(y)):\n",
        "        if(0.0<y[i]<=1.5):\n",
        "            y[i] = 1.0\n",
        "        elif(1.5<y[i]<=2.5):\n",
        "            y[i] = 2.0\n",
        "        elif(y[i]>=2.5):\n",
        "            y[i] = 3.0\n",
        "    return y\n",
        "def norm(x):\n",
        "  x_mean = x.mean(axis=0)\n",
        "  x_std = x.std(axis=0)\n",
        "  return (x - x_mean)/x_std\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmrRrkfWMX6K"
      },
      "source": [
        "class ANFIS:\n",
        "\n",
        "    def __init__(self, n_inputs, n_rules, learning_rate=1e-2):\n",
        "        self.n = n_inputs\n",
        "        self.m = n_rules\n",
        "        self.inputs = tf.placeholder(tf.float32, shape=(None, n_inputs))\n",
        "        self.targets = tf.placeholder(tf.float32, shape=None)\n",
        "        mu = tf.get_variable(\"mu\", [n_rules * n_inputs],\n",
        "                             initializer=tf.random_normal_initializer(0, 1))\n",
        "        sigma = tf.get_variable(\"sigma\", [n_rules * n_inputs],\n",
        "                                initializer=tf.random_normal_initializer(0, 1))\n",
        "        y = tf.get_variable(\"y\", [1, n_rules], initializer=tf.random_normal_initializer(0, 1))\n",
        "\n",
        "        self.params = tf.trainable_variables()\n",
        "\n",
        "        self.rul = tf.reduce_prod(\n",
        "            tf.reshape(tf.exp(-0.5 * tf.square(tf.subtract(tf.tile(self.inputs, (1, n_rules)), mu)) / tf.square(sigma)),\n",
        "                       (-1, n_rules, n_inputs)), axis=2)\n",
        "        num = tf.reduce_sum(tf.multiply(self.rul, y), axis=1)\n",
        "        den = tf.clip_by_value(tf.reduce_sum(self.rul, axis=1), 1e-12, 1e12)\n",
        "        self.out = tf.divide(num, den)\n",
        "\n",
        "        self.loss = tf.losses.huber_loss(self.targets, self.out)\n",
        "        self.optimize = tf.train.AdamOptimizer(learning_rate=alpha).minimize(self.loss)\n",
        "        self.init_variables = tf.global_variables_initializer()\n",
        "\n",
        "    def infer(self, sess, x, targets=None):\n",
        "        if targets is None:\n",
        "            return sess.run(self.out, feed_dict={self.inputs: x})\n",
        "        else:\n",
        "            return sess.run([self.out, self.loss], feed_dict={self.inputs: x, self.targets: targets})\n",
        "\n",
        "    def train(self, sess, x, targets):\n",
        "        yp, l, _ = sess.run([self.out, self.loss, self.optimize], feed_dict={self.inputs: x, self.targets: targets})\n",
        "        return l, yp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHkoPIRYMd9x"
      },
      "source": [
        "data = pd.read_excel('data5.xlsx')\n",
        "data = pd.DataFrame(data)\n",
        "data = np.asarray(data)\n",
        "y = data[:,-1]\n",
        "x = data[:,:-1]\n",
        "x = norm(x)\n",
        "x_tr, x_ts, y_tr, y_ts = train_test_split(x, y, test_size=0.3)\n",
        "m = x_tr.shape[0]\n",
        "n = x_tr.shape[1]\n",
        "m = 16\n",
        "alpha = 0.01\n",
        "epochs= 2000\n",
        "fis = ANFIS(n_inputs=7, n_rules=m, learning_rate=alpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0BbUc1AMrUx",
        "outputId": "0a8cf012-c1a6-415b-a31e-1b05b1dbc809"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(fis.init_variables)\n",
        "    trn_costs = []\n",
        "    val_costs = []\n",
        "    time_start = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        trn_loss, train_pred = fis.train(sess, x_tr, y_tr)\n",
        "        test_pred, val_loss = fis.infer(sess, x_ts, y_ts)\n",
        "        if epoch % 10 == 0:\n",
        "            print(\"Train cost after epoch %i: %f\" % (epoch, trn_loss))\n",
        "        if epoch == epochs - 1:\n",
        "            time_end = time.time()\n",
        "    # test_pred = set_up(test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train cost after epoch 0: 2.758087\n",
            "Train cost after epoch 10: 1.890719\n",
            "Train cost after epoch 20: 1.005263\n",
            "Train cost after epoch 30: 0.733375\n",
            "Train cost after epoch 40: 0.602317\n",
            "Train cost after epoch 50: 0.515588\n",
            "Train cost after epoch 60: 0.461412\n",
            "Train cost after epoch 70: 0.420105\n",
            "Train cost after epoch 80: 0.386443\n",
            "Train cost after epoch 90: 0.359610\n",
            "Train cost after epoch 100: 0.336551\n",
            "Train cost after epoch 110: 0.312233\n",
            "Train cost after epoch 120: 0.279278\n",
            "Train cost after epoch 130: 0.239620\n",
            "Train cost after epoch 140: 0.204457\n",
            "Train cost after epoch 150: 0.171830\n",
            "Train cost after epoch 160: 0.145179\n",
            "Train cost after epoch 170: 0.123807\n",
            "Train cost after epoch 180: 0.106152\n",
            "Train cost after epoch 190: 0.091536\n",
            "Train cost after epoch 200: 0.078320\n",
            "Train cost after epoch 210: 0.063156\n",
            "Train cost after epoch 220: 0.054764\n",
            "Train cost after epoch 230: 0.046705\n",
            "Train cost after epoch 240: 0.039894\n",
            "Train cost after epoch 250: 0.033571\n",
            "Train cost after epoch 260: 0.028213\n",
            "Train cost after epoch 270: 0.024815\n",
            "Train cost after epoch 280: 0.022637\n",
            "Train cost after epoch 290: 0.021155\n",
            "Train cost after epoch 300: 0.020226\n",
            "Train cost after epoch 310: 0.019593\n",
            "Train cost after epoch 320: 0.019125\n",
            "Train cost after epoch 330: 0.018752\n",
            "Train cost after epoch 340: 0.018432\n",
            "Train cost after epoch 350: 0.018139\n",
            "Train cost after epoch 360: 0.017867\n",
            "Train cost after epoch 370: 0.017619\n",
            "Train cost after epoch 380: 0.017385\n",
            "Train cost after epoch 390: 0.017158\n",
            "Train cost after epoch 400: 0.016939\n",
            "Train cost after epoch 410: 0.016731\n",
            "Train cost after epoch 420: 0.016537\n",
            "Train cost after epoch 430: 0.016358\n",
            "Train cost after epoch 440: 0.016254\n",
            "Train cost after epoch 450: 0.016684\n",
            "Train cost after epoch 460: 0.017945\n",
            "Train cost after epoch 470: 0.016326\n",
            "Train cost after epoch 480: 0.015878\n",
            "Train cost after epoch 490: 0.015683\n",
            "Train cost after epoch 500: 0.015527\n",
            "Train cost after epoch 510: 0.015402\n",
            "Train cost after epoch 520: 0.015290\n",
            "Train cost after epoch 530: 0.015182\n",
            "Train cost after epoch 540: 0.015081\n",
            "Train cost after epoch 550: 0.014985\n",
            "Train cost after epoch 560: 0.014889\n",
            "Train cost after epoch 570: 0.014899\n",
            "Train cost after epoch 580: 0.014999\n",
            "Train cost after epoch 590: 0.014669\n",
            "Train cost after epoch 600: 0.014410\n",
            "Train cost after epoch 610: 0.014157\n",
            "Train cost after epoch 620: 0.014245\n",
            "Train cost after epoch 630: 0.014115\n",
            "Train cost after epoch 640: 0.014478\n",
            "Train cost after epoch 650: 0.015151\n",
            "Train cost after epoch 660: 0.018866\n",
            "Train cost after epoch 670: 0.016437\n",
            "Train cost after epoch 680: 0.016101\n",
            "Train cost after epoch 690: 0.014941\n",
            "Train cost after epoch 700: 0.014637\n",
            "Train cost after epoch 710: 0.014407\n",
            "Train cost after epoch 720: 0.014286\n",
            "Train cost after epoch 730: 0.014178\n",
            "Train cost after epoch 740: 0.014090\n",
            "Train cost after epoch 750: 0.014012\n",
            "Train cost after epoch 760: 0.013942\n",
            "Train cost after epoch 770: 0.013879\n",
            "Train cost after epoch 780: 0.013922\n",
            "Train cost after epoch 790: 0.013836\n",
            "Train cost after epoch 800: 0.013958\n",
            "Train cost after epoch 810: 0.013869\n",
            "Train cost after epoch 820: 0.013852\n",
            "Train cost after epoch 830: 0.013836\n",
            "Train cost after epoch 840: 0.013817\n",
            "Train cost after epoch 850: 0.013815\n",
            "Train cost after epoch 860: 0.013881\n",
            "Train cost after epoch 870: 0.013826\n",
            "Train cost after epoch 880: 0.013870\n",
            "Train cost after epoch 890: 0.013910\n",
            "Train cost after epoch 900: 0.013789\n",
            "Train cost after epoch 910: 0.013868\n",
            "Train cost after epoch 920: 0.013814\n",
            "Train cost after epoch 930: 0.013869\n",
            "Train cost after epoch 940: 0.013909\n",
            "Train cost after epoch 950: 0.013787\n",
            "Train cost after epoch 960: 0.013854\n",
            "Train cost after epoch 970: 0.013829\n",
            "Train cost after epoch 980: 0.013754\n",
            "Train cost after epoch 990: 0.013783\n",
            "Train cost after epoch 1000: 0.013741\n",
            "Train cost after epoch 1010: 0.013774\n",
            "Train cost after epoch 1020: 0.013731\n",
            "Train cost after epoch 1030: 0.013740\n",
            "Train cost after epoch 1040: 0.013721\n",
            "Train cost after epoch 1050: 0.013707\n",
            "Train cost after epoch 1060: 0.013805\n",
            "Train cost after epoch 1070: 0.013722\n",
            "Train cost after epoch 1080: 0.013762\n",
            "Train cost after epoch 1090: 0.013727\n",
            "Train cost after epoch 1100: 0.013696\n",
            "Train cost after epoch 1110: 0.013749\n",
            "Train cost after epoch 1120: 0.013702\n",
            "Train cost after epoch 1130: 0.013698\n",
            "Train cost after epoch 1140: 0.013797\n",
            "Train cost after epoch 1150: 0.013764\n",
            "Train cost after epoch 1160: 0.014033\n",
            "Train cost after epoch 1170: 0.013863\n",
            "Train cost after epoch 1180: 0.013744\n",
            "Train cost after epoch 1190: 0.013685\n",
            "Train cost after epoch 1200: 0.013672\n",
            "Train cost after epoch 1210: 0.013662\n",
            "Train cost after epoch 1220: 0.013680\n",
            "Train cost after epoch 1230: 0.013657\n",
            "Train cost after epoch 1240: 0.013666\n",
            "Train cost after epoch 1250: 0.013643\n",
            "Train cost after epoch 1260: 0.013634\n",
            "Train cost after epoch 1270: 0.013678\n",
            "Train cost after epoch 1280: 0.013638\n",
            "Train cost after epoch 1290: 0.013667\n",
            "Train cost after epoch 1300: 0.013639\n",
            "Train cost after epoch 1310: 0.013648\n",
            "Train cost after epoch 1320: 0.013630\n",
            "Train cost after epoch 1330: 0.013621\n",
            "Train cost after epoch 1340: 0.013607\n",
            "Train cost after epoch 1350: 0.013606\n",
            "Train cost after epoch 1360: 0.013782\n",
            "Train cost after epoch 1370: 0.013647\n",
            "Train cost after epoch 1380: 0.013700\n",
            "Train cost after epoch 1390: 0.013723\n",
            "Train cost after epoch 1400: 0.013661\n",
            "Train cost after epoch 1410: 0.013609\n",
            "Train cost after epoch 1420: 0.013670\n",
            "Train cost after epoch 1430: 0.013696\n",
            "Train cost after epoch 1440: 0.013627\n",
            "Train cost after epoch 1450: 0.013586\n",
            "Train cost after epoch 1460: 0.013590\n",
            "Train cost after epoch 1470: 0.013591\n",
            "Train cost after epoch 1480: 0.013559\n",
            "Train cost after epoch 1490: 0.013578\n",
            "Train cost after epoch 1500: 0.013560\n",
            "Train cost after epoch 1510: 0.013554\n",
            "Train cost after epoch 1520: 0.013604\n",
            "Train cost after epoch 1530: 0.013566\n",
            "Train cost after epoch 1540: 0.013528\n",
            "Train cost after epoch 1550: 0.013600\n",
            "Train cost after epoch 1560: 0.013565\n",
            "Train cost after epoch 1570: 0.013531\n",
            "Train cost after epoch 1580: 0.013539\n",
            "Train cost after epoch 1590: 0.013545\n",
            "Train cost after epoch 1600: 0.013540\n",
            "Train cost after epoch 1610: 0.013616\n",
            "Train cost after epoch 1620: 0.013605\n",
            "Train cost after epoch 1630: 0.013569\n",
            "Train cost after epoch 1640: 0.013530\n",
            "Train cost after epoch 1650: 0.013506\n",
            "Train cost after epoch 1660: 0.013982\n",
            "Train cost after epoch 1670: 0.013832\n",
            "Train cost after epoch 1680: 0.013730\n",
            "Train cost after epoch 1690: 0.013586\n",
            "Train cost after epoch 1700: 0.013545\n",
            "Train cost after epoch 1710: 0.013537\n",
            "Train cost after epoch 1720: 0.013512\n",
            "Train cost after epoch 1730: 0.013581\n",
            "Train cost after epoch 1740: 0.013567\n",
            "Train cost after epoch 1750: 0.013528\n",
            "Train cost after epoch 1760: 0.013499\n",
            "Train cost after epoch 1770: 0.013565\n",
            "Train cost after epoch 1780: 0.013555\n",
            "Train cost after epoch 1790: 0.013522\n",
            "Train cost after epoch 1800: 0.013492\n",
            "Train cost after epoch 1810: 0.013554\n",
            "Train cost after epoch 1820: 0.013610\n",
            "Train cost after epoch 1830: 0.013541\n",
            "Train cost after epoch 1840: 0.013500\n",
            "Train cost after epoch 1850: 0.013730\n",
            "Train cost after epoch 1860: 0.013621\n",
            "Train cost after epoch 1870: 0.013587\n",
            "Train cost after epoch 1880: 0.013800\n",
            "Train cost after epoch 1890: 0.014241\n",
            "Train cost after epoch 1900: 0.013888\n",
            "Train cost after epoch 1910: 0.013676\n",
            "Train cost after epoch 1920: 0.013617\n",
            "Train cost after epoch 1930: 0.013560\n",
            "Train cost after epoch 1940: 0.013470\n",
            "Train cost after epoch 1950: 0.014105\n",
            "Train cost after epoch 1960: 0.014704\n",
            "Train cost after epoch 1970: 0.014017\n",
            "Train cost after epoch 1980: 0.013816\n",
            "Train cost after epoch 1990: 0.013727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2L_gCI9Mv3Z",
        "outputId": "a04f5503-810c-4e3f-ce24-20b32c6332e2"
      },
      "source": [
        "yp = test_pred # Get the predictions\n",
        "\n",
        "yp = set(yp)\n",
        "\n",
        "y_actual = pd.Series(y_ts, name='Actual')\n",
        "y_pred = pd.Series(yp, name='Predicted')\n",
        "confmat = pd.crosstab(y_actual, y_pred)\n",
        "print(confmat)\n",
        "\n",
        "confmat = np.asarray(confmat)\n",
        "Accuracy = float(confmat[0][0]+confmat[1][1]+confmat[2][2])/float(yp.shape[0])\n",
        "print('Accuracy :' + ' ' + str(Accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted  1.0  2.0  3.0\n",
            "Actual                  \n",
            "1.0         20    0    0\n",
            "2.0          3   15    0\n",
            "3.0          2    0   23\n",
            "Accuracy : 92.06349206349206\n"
          ]
        }
      ]
    }
  ]
}